/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
25/03/09 14:10:29 WARN Utils: Your hostname, Rachits-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.201 instead (on interface en0)
25/03/09 14:10:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
:: loading settings :: url = jar:file:/opt/homebrew/Cellar/apache-spark/3.5.1/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /Users/rachitmishra/.ivy2/cache
The jars for the packages stored in: /Users/rachitmishra/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-491fe590-4902-4503-acad-a728b041e2c8;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
	found org.apache.kafka#kafka-clients;3.4.1 in local-m2-cache
	found org.lz4#lz4-java;1.8.0 in local-m2-cache
	found org.xerial.snappy#snappy-java;1.1.10.3 in central
	found org.slf4j#slf4j-api;2.0.7 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.apache.commons#commons-pool2;2.11.1 in central
	found com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central
	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central
	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
	found com.datastax.oss#native-protocol;1.5.0 in central
	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
	found com.typesafe#config;1.4.1 in central
	found io.dropwizard.metrics#metrics-core;4.1.18 in central
	found org.hdrhistogram#HdrHistogram;2.1.12 in central
	found org.reactivestreams#reactive-streams;1.0.3 in central
	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
	found com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache
	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
	found org.apache.commons#commons-lang3;3.10 in central
	found com.thoughtworks.paranamer#paranamer;2.8 in central
	found org.scala-lang#scala-reflect;2.12.11 in central
:: resolution report :: resolve 388ms :: artifacts dl 10ms
	:: modules in use:
	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
	com.datastax.oss#native-protocol;1.5.0 from central in [default]
	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]
	com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]
	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
	com.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]
	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
	com.typesafe#config;1.4.1 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
	org.apache.commons#commons-lang3;3.10 from central in [default]
	org.apache.commons#commons-pool2;2.11.1 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
	org.apache.kafka#kafka-clients;3.4.1 from local-m2-cache in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
	org.lz4#lz4-java;1.8.0 from local-m2-cache in [default]
	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
	org.scala-lang#scala-reflect;2.12.11 from central in [default]
	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
	org.slf4j#slf4j-api;2.0.7 from central in [default]
	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
	:: evicted modules:
	com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   30  |   0   |   0   |   2   ||   28  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-491fe590-4902-4503-acad-a728b041e2c8
	confs: [default]
	0 artifacts copied, 28 already retrieved (0kB/8ms)
25/03/09 14:10:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/09 14:10:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/03/09 14:10:31 INFO SharedState: Warehouse path is 'file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark-warehouse'.
2025-03-09 14:10:32,140 - INFO - Setting up ScyllaDB...
2025-03-09 14:10:32,141 - WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['localhost'], lbp = None)
2025-03-09 14:10:32,253 - WARNING - Downgrading core protocol version from 66 to 65 for ::1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-03-09 14:10:32,261 - WARNING - Downgrading core protocol version from 65 to 5 for ::1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-03-09 14:10:32,272 - WARNING - Downgrading core protocol version from 5 to 4 for ::1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-03-09 14:10:32,278 - WARNING - An authentication challenge was not sent, this is suspicious because the driver expects authentication (configured authenticator = PlainTextAuthenticator)
2025-03-09 14:10:32,285 - INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '::1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
2025-03-09 14:10:32,285 - INFO - Cassandra host 127.0.0.1:9042 removed
2025-03-09 14:10:32,296 - WARNING - An authentication challenge was not sent, this is suspicious because the driver expects authentication (configured authenticator = PlainTextAuthenticator)
2025-03-09 14:10:32,296 - INFO - Creating keyspace...
2025-03-09 14:10:32,299 - WARNING - Server warning: SimpleStrategy replication class is not recommended, but was used for keyspace geopolitics. You may suppress this warning by delisting SimpleStrategy from replication_strategy_warn_list configuration option, or make it into an error by listing this replication strategy on replication_strategy_fail_list.
2025-03-09 14:10:32,299 - WARNING - Server warning: Using Replication Factor replication_factor=1 lower than the minimum_replication_factor_warn_threshold=3 is not recommended.
2025-03-09 14:10:32,308 - INFO - Table 'articles' already exists, checking for required columns...
2025-03-09 14:10:32,309 - INFO - Found columns: {'processed_at', 'socialimage', 'language', 'title', 'domain', 'sentiment', 'sourcecountry', 'seendate', 'url'}
2025-03-09 14:10:32,309 - INFO - ScyllaDB setup completed successfully
2025-03-09 14:10:32,310 - INFO - Created checkpoint directory at /Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint
2025-03-09 14:10:32,310 - INFO - Starting Spark Streaming...
2025-03-09 14:10:32,910 - INFO - Callback Server Starting
2025-03-09 14:10:32,910 - INFO - Socket listening on ('127.0.0.1', 55768)
25/03/09 14:10:32 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/03/09 14:10:32 INFO ResolveWriteToStream: Checkpoint root /Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint resolved to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint.
25/03/09 14:10:32 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
25/03/09 14:10:33 INFO MicroBatchExecution: Starting [id = f5703bd5-3704-48be-97ba-9d131710e782, runId = cfa692d0-1274-437d-bbea-855da0f43323]. Use file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint to store the query checkpoint.
2025-03-09 14:10:33,068 - INFO - Spark Streaming started successfully
25/03/09 14:10:33 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@160afd28] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@58723feb]
25/03/09 14:10:33 INFO OffsetSeqLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32
25/03/09 14:10:33 INFO OffsetSeqLog: Getting latest batch 32
25/03/09 14:10:33 INFO OffsetSeqLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32
25/03/09 14:10:33 INFO OffsetSeqLog: Getting latest batch 32
25/03/09 14:10:33 INFO CommitLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32
25/03/09 14:10:33 INFO CommitLog: Getting latest batch 32
25/03/09 14:10:33 INFO MicroBatchExecution: Resuming at batch 33 with committed offsets {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":5650}}} and available offsets {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":5650}}}
25/03/09 14:10:33 INFO MicroBatchExecution: Stream started from {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":5650}}}
25/03/09 14:10:33 INFO AdminClientConfig: AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

25/03/09 14:10:33 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, heartbeat.interval.ms, consumer.polltimeoutms, session.timeout.ms, auto.offset.reset]' were supplied but are not used yet.
25/03/09 14:10:33 INFO AppInfoParser: Kafka version: 3.4.1
25/03/09 14:10:33 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
25/03/09 14:10:33 INFO AppInfoParser: Kafka startTimeMs: 1741509633274
25/03/09 14:10:33 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/33 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.33.1991e3b1-a946-4b13-ba2e-0fa8e3af5ea9.tmp
25/03/09 14:10:33 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.33.1991e3b1-a946-4b13-ba2e-0fa8e3af5ea9.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/33
25/03/09 14:10:33 INFO MicroBatchExecution: Committed offsets for batch 33. Metadata OffsetSeqMetadata(0,1741509633613,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:10:33 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:10:33 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:10:33 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:10:33 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 121.691167 ms
2025-03-09 14:10:34,292 - INFO - Python Server ready to receive messages
2025-03-09 14:10:34,292 - INFO - Received command c on object id p0
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 4.562083 ms
25/03/09 14:10:34 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:34 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:34 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:34 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:10:34 INFO DAGScheduler: Missing parents: List()
25/03/09 14:10:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 42.2 KiB, free 2.2 GiB)
25/03/09 14:10:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2.2 GiB)
25/03/09 14:10:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2.2 GiB)
25/03/09 14:10:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/03/09 14:10:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:10:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 22.476958 ms
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 20.910625 ms
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 3.809833 ms
25/03/09 14:10:34 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=0 partitionId=0
[Stage 0:>                                                          (0 + 1) / 1]25/03/09 14:10:34 INFO CodeGenerator: Code generated in 19.085042 ms
25/03/09 14:10:34 INFO CodeGenerator: Code generated in 23.878917 ms
25/03/09 14:10:34 INFO ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor
	group.instance.id = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

25/03/09 14:10:35 WARN ConsumerConfig: These configurations '[consumer.polltimeoutms]' were supplied but are not used yet.
25/03/09 14:10:35 INFO AppInfoParser: Kafka version: 3.4.1
25/03/09 14:10:35 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
25/03/09 14:10:35 INFO AppInfoParser: Kafka startTimeMs: 1741509635004
25/03/09 14:10:35 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Assigned to partition(s): geopolitics_events-0
25/03/09 14:10:35 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:35 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting the last seen epoch of partition geopolitics_events-0 to 0 since the associated topicId changed from null to 7q44BmEVR9Wx073grjT5UA
25/03/09 14:10:35 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Cluster ID: cC0RBr0YTemVr0RoeHLx5A
25/03/09 14:10:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:10:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:35 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 584660208 nanos, during time span of 671665750 nanos.
25/03/09 14:10:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1914 bytes result sent to driver
25/03/09 14:10:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1019 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/03/09 14:10:35 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 1.353 s
25/03/09 14:10:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/03/09 14:10:35 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 1.375951 s
                                                                                25/03/09 14:10:35 INFO CodeGenerator: Code generated in 7.060792 ms
25/03/09 14:10:35 INFO CodeGenerator: Code generated in 5.438417 ms
25/03/09 14:10:35 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:35 INFO DAGScheduler: Registering RDD 8 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/03/09 14:10:35 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:35 INFO DAGScheduler: Final stage: ResultStage 2 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/03/09 14:10:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
25/03/09 14:10:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 45.1 KiB, free 2.2 GiB)
25/03/09 14:10:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2.2 GiB)
25/03/09 14:10:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.201:55761 (size: 17.2 KiB, free: 2.2 GiB)
25/03/09 14:10:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/03/09 14:10:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:10:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/03/09 14:10:35 INFO CodeGenerator: Code generated in 5.247542 ms
25/03/09 14:10:35 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=1 partitionId=0
25/03/09 14:10:35 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:10:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:36 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 519909583 nanos, during time span of 541296000 nanos.
25/03/09 14:10:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2344 bytes result sent to driver
25/03/09 14:10:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 587 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/03/09 14:10:36 INFO DAGScheduler: ShuffleMapStage 1 (start at NativeMethodAccessorImpl.java:0) finished in 0.597 s
25/03/09 14:10:36 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:10:36 INFO DAGScheduler: running: Set()
25/03/09 14:10:36 INFO DAGScheduler: waiting: Set(ResultStage 2)
25/03/09 14:10:36 INFO DAGScheduler: failed: Set()
25/03/09 14:10:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/03/09 14:10:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:10:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/03/09 14:10:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:10:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
25/03/09 14:10:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.201:55761 in memory (size: 17.2 KiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO CodeGenerator: Code generated in 10.137959 ms
25/03/09 14:10:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4038 bytes result sent to driver
25/03/09 14:10:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/03/09 14:10:36 INFO DAGScheduler: ResultStage 2 (start at NativeMethodAccessorImpl.java:0) finished in 0.081 s
25/03/09 14:10:36 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/03/09 14:10:36 INFO DAGScheduler: Job 1 finished: start at NativeMethodAccessorImpl.java:0, took 0.701224 s
2025-03-09 14:10:36,540 - INFO - Processing batch 33 with 50 records
2025-03-09 14:10:36,540 - INFO - Applying sentiment analysis...
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 264.0 B, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece1 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece2 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece3 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece4 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece4 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece5 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece5 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece6 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece6 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece7 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece7 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece8 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece8 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece9 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece9 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece10 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece10 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece11 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece11 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece12 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece12 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece13 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece13 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece14 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece14 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece15 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece15 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece16 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece16 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece17 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece17 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece18 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece18 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece19 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece19 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece20 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece20 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece21 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece21 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece22 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece22 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece23 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece23 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece24 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece24 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece25 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece25 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece26 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece26 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece27 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece27 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece28 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece28 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece29 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece29 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece30 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece30 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece31 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece31 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece32 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece32 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece33 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece33 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece34 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece34 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece35 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece35 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece36 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece36 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece37 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece37 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece38 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece38 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece39 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece39 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece40 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece40 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece41 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece41 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece42 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece42 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece43 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece43 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece44 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece44 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece45 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece45 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece46 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece46 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece47 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece47 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece48 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece48 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece49 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece49 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece50 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece50 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece51 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece51 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece52 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece52 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece53 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece53 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece54 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece54 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece55 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece55 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece56 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece56 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece57 stored as bytes in memory (estimated size 4.0 MiB, free 2045.6 MiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece57 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2045.6 MiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece58 stored as bytes in memory (estimated size 4.0 MiB, free 2041.6 MiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece58 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2041.6 MiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece59 stored as bytes in memory (estimated size 4.0 MiB, free 2037.6 MiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece59 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2037.6 MiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece60 stored as bytes in memory (estimated size 4.0 MiB, free 2033.6 MiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece60 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2033.6 MiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece61 stored as bytes in memory (estimated size 4.0 MiB, free 2029.6 MiB)
25/03/09 14:10:36 INFO BlockManagerInfo: Added broadcast_3_piece61 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2029.6 MiB)
25/03/09 14:10:36 INFO MemoryStore: Block broadcast_3_piece62 stored as bytes in memory (estimated size 4.0 MiB, free 2025.6 MiB)
25/03/09 14:10:37 INFO BlockManagerInfo: Added broadcast_3_piece62 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2025.6 MiB)
25/03/09 14:10:37 INFO MemoryStore: Block broadcast_3_piece63 stored as bytes in memory (estimated size 4.0 MiB, free 2021.6 MiB)
25/03/09 14:10:37 INFO BlockManagerInfo: Added broadcast_3_piece63 in memory on 192.168.0.201:55761 (size: 4.0 MiB, free: 2021.6 MiB)
25/03/09 14:10:37 INFO MemoryStore: Block broadcast_3_piece64 stored as bytes in memory (estimated size 1189.2 KiB, free 2020.4 MiB)
25/03/09 14:10:37 INFO BlockManagerInfo: Added broadcast_3_piece64 in memory on 192.168.0.201:55761 (size: 1189.2 KiB, free: 2020.4 MiB)
25/03/09 14:10:37 INFO SparkContext: Created broadcast 3 from start at NativeMethodAccessorImpl.java:0
2025-03-09 14:10:37,029 - INFO - DataFrame schema:
2025-03-09 14:10:37,031 - INFO - Sample of processed data:
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 9.218083 ms
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 6.790958 ms
25/03/09 14:10:37 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:37 INFO DAGScheduler: Got job 2 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:37 INFO DAGScheduler: Final stage: ResultStage 3 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:37 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:10:37 INFO DAGScheduler: Missing parents: List()
25/03/09 14:10:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 55.8 KiB, free 2020.4 MiB)
25/03/09 14:10:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.4 MiB)
25/03/09 14:10:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:10:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/03/09 14:10:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:10:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 14.16475 ms
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 4.244834 ms
25/03/09 14:10:37 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=3 partitionId=0
25/03/09 14:10:37 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:37 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 8.785125 ms
25/03/09 14:10:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:10:37 INFO CodeGenerator: Code generated in 8.717417 ms
[Stage 3:>                                                          (0 + 1) / 1]25/03/09 14:10:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:39 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 529043958 nanos, during time span of 2138849792 nanos.
25/03/09 14:10:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 3467 bytes result sent to driver
25/03/09 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 2545 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/03/09 14:10:39 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 55762
25/03/09 14:10:39 INFO DAGScheduler: ResultStage 3 (start at NativeMethodAccessorImpl.java:0) finished in 2.557 s
25/03/09 14:10:39 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/03/09 14:10:39 INFO DAGScheduler: Job 2 finished: start at NativeMethodAccessorImpl.java:0, took 2.560806 s
                                                                                25/03/09 14:10:40 INFO CodeGenerator: Code generated in 7.102875 ms
2025-03-09 14:10:40,202 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:10:40,203 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:10:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:40 INFO DAGScheduler: Registering RDD 18 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/03/09 14:10:40 INFO DAGScheduler: Got job 3 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:40 INFO DAGScheduler: Final stage: ResultStage 5 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/03/09 14:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
25/03/09 14:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:10:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.201:55761 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/03/09 14:10:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:10:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
25/03/09 14:10:40 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=4 partitionId=0
25/03/09 14:10:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 4:>                                                          (0 + 1) / 1]25/03/09 14:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:40 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 526321458 nanos, during time span of 539745875 nanos.
25/03/09 14:10:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2387 bytes result sent to driver
25/03/09 14:10:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 559 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/03/09 14:10:40 INFO DAGScheduler: ShuffleMapStage 4 (start at NativeMethodAccessorImpl.java:0) finished in 0.586 s
25/03/09 14:10:40 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:10:40 INFO DAGScheduler: running: Set()
25/03/09 14:10:40 INFO DAGScheduler: waiting: Set(ResultStage 5)
25/03/09 14:10:40 INFO DAGScheduler: failed: Set()
25/03/09 14:10:40 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:10:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/03/09 14:10:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:10:40 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
25/03/09 14:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:10:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 3995 bytes result sent to driver
25/03/09 14:10:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/03/09 14:10:40 INFO DAGScheduler: ResultStage 5 (start at NativeMethodAccessorImpl.java:0) finished in 0.011 s
25/03/09 14:10:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/03/09 14:10:40 INFO DAGScheduler: Job 3 finished: start at NativeMethodAccessorImpl.java:0, took 0.601067 s
                                                                                2025-03-09 14:10:40,830 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:10:40,830 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:10:40 INFO CodeGenerator: Code generated in 6.338542 ms
25/03/09 14:10:40 INFO CodeGenerator: Code generated in 4.273125 ms
25/03/09 14:10:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:40 INFO DAGScheduler: Got job 4 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:40 INFO DAGScheduler: Final stage: ResultStage 6 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:40 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:10:40 INFO DAGScheduler: Missing parents: List()
25/03/09 14:10:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:10:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:10:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/03/09 14:10:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.201:55761 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:10:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
25/03/09 14:10:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:10:40 INFO CodeGenerator: Code generated in 5.1385 ms
25/03/09 14:10:40 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=6 partitionId=0
25/03/09 14:10:40 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:40 INFO CodeGenerator: Code generated in 4.720667 ms
25/03/09 14:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 6:>                                                          (0 + 1) / 1]25/03/09 14:10:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:43 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 525436500 nanos, during time span of 2098760333 nanos.
25/03/09 14:10:43 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3994 bytes result sent to driver
25/03/09 14:10:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 2135 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:43 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/03/09 14:10:43 INFO DAGScheduler: ResultStage 6 (start at NativeMethodAccessorImpl.java:0) finished in 2.145 s
25/03/09 14:10:43 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/03/09 14:10:43 INFO DAGScheduler: Job 4 finished: start at NativeMethodAccessorImpl.java:0, took 2.148976 s
                                                                                25/03/09 14:10:43 INFO ContactPoints: Contact point localhost:9042 resolves to multiple addresses, will use them all ([localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1])
25/03/09 14:10:43 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
25/03/09 14:10:43 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:10:43 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:41)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at com.datastax.oss.driver.internal.core.util.Reflection.resolveClass(Reflection.java:329)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:235)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:110)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:377)
	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:773)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
	... 26 more
25/03/09 14:10:43 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 WARN PlainTextAuthProviderBase: [] localhost/0:0:0:0:0:0:0:1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:10:43 INFO CassandraConnector: Connected to Cassandra cluster.
25/03/09 14:10:44 INFO CodeGenerator: Code generated in 5.541625 ms
25/03/09 14:10:44 INFO CodeGenerator: Code generated in 5.340125 ms
25/03/09 14:10:44 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@40c4de90,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b80a998). The input RDD has 1 partitions.
25/03/09 14:10:44 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:10:44 INFO DAGScheduler: Got job 5 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:10:44 INFO DAGScheduler: Final stage: ResultStage 7 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:10:44 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:10:44 INFO DAGScheduler: Missing parents: List()
25/03/09 14:10:44 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:10:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 60.9 KiB, free 2020.4 MiB)
25/03/09 14:10:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.4 MiB)
25/03/09 14:10:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.201:55761 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:10:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/03/09 14:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:10:44 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/03/09 14:10:44 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:10:44 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
25/03/09 14:10:44 INFO CodeGenerator: Code generated in 3.832417 ms
25/03/09 14:10:44 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5650 untilOffset=5700, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=33 taskId=7 partitionId=0
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5650 for partition geopolitics_events-0
25/03/09 14:10:44 INFO CodeGenerator: Code generated in 6.730125 ms
25/03/09 14:10:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:10:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:10:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5700, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:10:44 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 7:>                                                          (0 + 1) / 1]25/03/09 14:10:47 INFO PythonUDFRunner: Times: total = 3075, boot = 13, init = 1710, finish = 1352
25/03/09 14:10:47 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 7, attempt 0, stage 7.0)
25/03/09 14:10:47 INFO DataWritingSparkTask: Committed partition 0 (task 7, attempt 0, stage 7.0)
25/03/09 14:10:47 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 515206375 nanos, during time span of 3200240084 nanos.
25/03/09 14:10:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2691 bytes result sent to driver
25/03/09 14:10:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 3268 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:10:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/03/09 14:10:47 INFO DAGScheduler: ResultStage 7 (start at NativeMethodAccessorImpl.java:0) finished in 3.278 s
25/03/09 14:10:47 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:10:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/03/09 14:10:47 INFO DAGScheduler: Job 5 finished: start at NativeMethodAccessorImpl.java:0, took 3.281426 s
                                                                                25/03/09 14:10:47 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@40c4de90,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b80a998) is committing.
25/03/09 14:10:47 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@40c4de90,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b80a998) committed.
2025-03-09 14:10:47,345 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:10:47,345 - INFO - Successfully processed batch 33
25/03/09 14:10:47 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/33 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.33.25a2ac61-30da-4b2f-9279-be37a94fa6d4.tmp
25/03/09 14:10:47 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.33.25a2ac61-30da-4b2f-9279-be37a94fa6d4.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/33
25/03/09 14:10:47 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:40:33.094Z",
  "batchId" : 33,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 11.194290911635067,
  "durationMs" : {
    "addBatch" : 13424,
    "commitOffsets" : 36,
    "getBatch" : 2,
    "latestOffset" : 449,
    "queryPlanning" : 259,
    "triggerExecution" : 14292,
    "walCommit" : 44
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5650
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5700
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5700
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 11.194290911635067,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:10:47 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 14319 milliseconds
25/03/09 14:11:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:11:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:11:30 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/34 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.34.8f65e3f5-feb4-4d76-a5ce-0ec4438acd63.tmp
25/03/09 14:11:30 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.34.8f65e3f5-feb4-4d76-a5ce-0ec4438acd63.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/34
25/03/09 14:11:30 INFO MicroBatchExecution: Committed offsets for batch 34. Metadata OffsetSeqMetadata(0,1741509690018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:11:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:11:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:11:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:11:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:11:30,086 - INFO - Received command c on object id p0
25/03/09 14:11:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:30 INFO DAGScheduler: Got job 6 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:30 INFO DAGScheduler: Final stage: ResultStage 8 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:30 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:11:30 INFO DAGScheduler: Missing parents: List()
25/03/09 14:11:30 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:11:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:11:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:11:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/03/09 14:11:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:11:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.0.201:55761 in memory (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:11:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/03/09 14:11:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=8 partitionId=0
25/03/09 14:11:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:30 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 538227250 nanos, during time span of 549054292 nanos.
25/03/09 14:11:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1914 bytes result sent to driver
25/03/09 14:11:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 561 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/03/09 14:11:30 INFO DAGScheduler: ResultStage 8 (start at NativeMethodAccessorImpl.java:0) finished in 0.574 s
25/03/09 14:11:30 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/03/09 14:11:30 INFO DAGScheduler: Job 6 finished: start at NativeMethodAccessorImpl.java:0, took 0.578192 s
25/03/09 14:11:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:30 INFO DAGScheduler: Registering RDD 39 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/03/09 14:11:30 INFO DAGScheduler: Got job 7 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:30 INFO DAGScheduler: Final stage: ResultStage 10 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/03/09 14:11:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
25/03/09 14:11:30 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:11:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:11:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:11:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/03/09 14:11:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:11:30 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/03/09 14:11:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=9 partitionId=0
25/03/09 14:11:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 514948500 nanos, during time span of 520033750 nanos.
25/03/09 14:11:31 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2387 bytes result sent to driver
25/03/09 14:11:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 539 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/03/09 14:11:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:11:31 INFO DAGScheduler: ShuffleMapStage 9 (start at NativeMethodAccessorImpl.java:0) finished in 0.542 s
25/03/09 14:11:31 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:11:31 INFO DAGScheduler: running: Set()
25/03/09 14:11:31 INFO DAGScheduler: waiting: Set(ResultStage 10)
25/03/09 14:11:31 INFO DAGScheduler: failed: Set()
25/03/09 14:11:31 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:11:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:11:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:11:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/03/09 14:11:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:11:31 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
25/03/09 14:11:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:11:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:11:31 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 3995 bytes result sent to driver
25/03/09 14:11:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/03/09 14:11:31 INFO DAGScheduler: ResultStage 10 (start at NativeMethodAccessorImpl.java:0) finished in 0.012 s
25/03/09 14:11:31 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/03/09 14:11:31 INFO DAGScheduler: Job 7 finished: start at NativeMethodAccessorImpl.java:0, took 0.559565 s
2025-03-09 14:11:31,275 - INFO - Processing batch 34 with 50 records
2025-03-09 14:11:31,275 - INFO - Applying sentiment analysis...
2025-03-09 14:11:31,299 - INFO - DataFrame schema:
2025-03-09 14:11:31,299 - INFO - Sample of processed data:
25/03/09 14:11:31 INFO CodeGenerator: Code generated in 7.674417 ms
25/03/09 14:11:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:31 INFO DAGScheduler: Got job 8 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:31 INFO DAGScheduler: Final stage: ResultStage 11 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:31 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:11:31 INFO DAGScheduler: Missing parents: List()
25/03/09 14:11:31 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[47] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:11:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:11:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:11:31 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[47] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/03/09 14:11:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:11:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
25/03/09 14:11:31 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:11:31 INFO CodeGenerator: Code generated in 3.84875 ms
25/03/09 14:11:31 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=11 partitionId=0
25/03/09 14:11:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:11:31 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 11:>                                                         (0 + 1) / 1]25/03/09 14:11:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 530032375 nanos, during time span of 670527792 nanos.
25/03/09 14:11:32 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 3467 bytes result sent to driver
25/03/09 14:11:32 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 700 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:32 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/03/09 14:11:32 INFO DAGScheduler: ResultStage 11 (start at NativeMethodAccessorImpl.java:0) finished in 0.717 s
25/03/09 14:11:32 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/03/09 14:11:32 INFO DAGScheduler: Job 8 finished: start at NativeMethodAccessorImpl.java:0, took 0.721774 s
                                                                                root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:10:37.047171|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:10:37.047171|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:10:40.848353|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:10:40.848353|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:10:40.848353| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:10:40.848353| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:10:40.848353|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:11:32,140 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:11:32,141 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:11:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:32 INFO DAGScheduler: Registering RDD 49 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/03/09 14:11:32 INFO DAGScheduler: Got job 9 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:32 INFO DAGScheduler: Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/03/09 14:11:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
25/03/09 14:11:32 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[49] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:11:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[49] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:32 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/03/09 14:11:32 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:11:32 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
25/03/09 14:11:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=12 partitionId=0
25/03/09 14:11:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 518266625 nanos, during time span of 523680167 nanos.
25/03/09 14:11:32 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2387 bytes result sent to driver
25/03/09 14:11:32 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 550 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:32 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/03/09 14:11:32 INFO DAGScheduler: ShuffleMapStage 12 (start at NativeMethodAccessorImpl.java:0) finished in 0.563 s
25/03/09 14:11:32 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:11:32 INFO DAGScheduler: running: Set()
25/03/09 14:11:32 INFO DAGScheduler: waiting: Set(ResultStage 13)
25/03/09 14:11:32 INFO DAGScheduler: failed: Set()
25/03/09 14:11:32 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[52] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:11:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[52] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/03/09 14:11:32 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:11:32 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
25/03/09 14:11:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:11:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:11:32 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3995 bytes result sent to driver
25/03/09 14:11:32 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 8 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:32 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/03/09 14:11:32 INFO DAGScheduler: ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 0.012 s
25/03/09 14:11:32 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/03/09 14:11:32 INFO DAGScheduler: Job 9 finished: start at NativeMethodAccessorImpl.java:0, took 0.578434 s
2025-03-09 14:11:32,744 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:11:32,744 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:11:32 INFO CodeGenerator: Code generated in 4.391541 ms
25/03/09 14:11:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:32 INFO DAGScheduler: Got job 10 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:32 INFO DAGScheduler: Final stage: ResultStage 14 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:32 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:11:32 INFO DAGScheduler: Missing parents: List()
25/03/09 14:11:32 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:11:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:11:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:32 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/03/09 14:11:32 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:11:32 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
25/03/09 14:11:32 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:11:32 INFO CodeGenerator: Code generated in 5.790125 ms
25/03/09 14:11:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=14 partitionId=0
25/03/09 14:11:32 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 14:>                                                         (0 + 1) / 1]25/03/09 14:11:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 527951041 nanos, during time span of 2241788542 nanos.
25/03/09 14:11:35 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3994 bytes result sent to driver
25/03/09 14:11:35 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 2280 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:35 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/03/09 14:11:35 INFO DAGScheduler: ResultStage 14 (start at NativeMethodAccessorImpl.java:0) finished in 2.292 s
25/03/09 14:11:35 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/03/09 14:11:35 INFO DAGScheduler: Job 10 finished: start at NativeMethodAccessorImpl.java:0, took 2.296234 s
                                                                                25/03/09 14:11:35 INFO CodeGenerator: Code generated in 5.142792 ms
25/03/09 14:11:35 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@3f3db290,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@510a60b9). The input RDD has 1 partitions.
25/03/09 14:11:35 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:11:35 INFO DAGScheduler: Got job 11 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:11:35 INFO DAGScheduler: Final stage: ResultStage 15 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:11:35 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:11:35 INFO DAGScheduler: Missing parents: List()
25/03/09 14:11:35 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[61] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:11:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:11:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 2020.3 MiB)
25/03/09 14:11:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.0.201:55761 (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:11:35 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
25/03/09 14:11:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:11:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[61] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:11:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/03/09 14:11:35 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:11:35 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
25/03/09 14:11:35 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5700 untilOffset=5750, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=34 taskId=15 partitionId=0
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5700 for partition geopolitics_events-0
25/03/09 14:11:35 INFO CodeGenerator: Code generated in 7.4875 ms
25/03/09 14:11:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:11:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:11:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5750, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:11:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 15:>                                                         (0 + 1) / 1]25/03/09 14:11:38 INFO PythonUDFRunner: Times: total = 3209, boot = 3, init = 1765, finish = 1441
25/03/09 14:11:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 15, attempt 0, stage 15.0)
25/03/09 14:11:38 INFO DataWritingSparkTask: Committed partition 0 (task 15, attempt 0, stage 15.0)
25/03/09 14:11:38 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 517055000 nanos, during time span of 3315697791 nanos.
25/03/09 14:11:38 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2691 bytes result sent to driver
25/03/09 14:11:38 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 3342 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:11:38 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/03/09 14:11:38 INFO DAGScheduler: ResultStage 15 (start at NativeMethodAccessorImpl.java:0) finished in 3.351 s
25/03/09 14:11:38 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:11:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/03/09 14:11:38 INFO DAGScheduler: Job 11 finished: start at NativeMethodAccessorImpl.java:0, took 3.354812 s
                                                                                25/03/09 14:11:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@3f3db290,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@510a60b9) is committing.
25/03/09 14:11:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@3f3db290,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@510a60b9) committed.
2025-03-09 14:11:38,534 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:11:38,534 - INFO - Successfully processed batch 34
25/03/09 14:11:38 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/34 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.34.0a46c73f-bc0d-49e5-8627-52e923b9d4d8.tmp
25/03/09 14:11:38 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.34.0a46c73f-bc0d-49e5-8627-52e923b9d4d8.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/34
25/03/09 14:11:38 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:41:30.002Z",
  "batchId" : 34,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.00480144043213,
  "processedRowsPerSecond" : 18.64801864801865,
  "durationMs" : {
    "addBatch" : 8464,
    "commitOffsets" : 48,
    "getBatch" : 0,
    "latestOffset" : 16,
    "queryPlanning" : 10,
    "triggerExecution" : 8580,
    "walCommit" : 41
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5700
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5750
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5750
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.00480144043213,
    "processedRowsPerSecond" : 18.64801864801865,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:11:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:12:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:12:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:12:30 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/35 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.35.3cd8e510-47d7-4d13-bac3-932bb5c185ca.tmp
25/03/09 14:12:30 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.35.3cd8e510-47d7-4d13-bac3-932bb5c185ca.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/35
25/03/09 14:12:30 INFO MicroBatchExecution: Committed offsets for batch 35. Metadata OffsetSeqMetadata(0,1741509750019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:12:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:12:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:12:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:12:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:12:30,071 - INFO - Received command c on object id p0
25/03/09 14:12:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:30 INFO DAGScheduler: Got job 12 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:30 INFO DAGScheduler: Final stage: ResultStage 16 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:30 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:12:30 INFO DAGScheduler: Missing parents: List()
25/03/09 14:12:30 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:12:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:12:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:12:30 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.0.201:55761 in memory (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:30 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:30 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
25/03/09 14:12:30 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:12:30 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
25/03/09 14:12:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=16 partitionId=0
25/03/09 14:12:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:30 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 531264291 nanos, during time span of 539224583 nanos.
25/03/09 14:12:30 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1914 bytes result sent to driver
25/03/09 14:12:30 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 550 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:30 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
25/03/09 14:12:30 INFO DAGScheduler: ResultStage 16 (start at NativeMethodAccessorImpl.java:0) finished in 0.559 s
25/03/09 14:12:30 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
25/03/09 14:12:30 INFO DAGScheduler: Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 0.563121 s
25/03/09 14:12:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:30 INFO DAGScheduler: Registering RDD 70 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/03/09 14:12:30 INFO DAGScheduler: Got job 13 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:30 INFO DAGScheduler: Final stage: ResultStage 18 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
25/03/09 14:12:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
25/03/09 14:12:30 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[70] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:12:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:12:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:30 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[70] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:30 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/03/09 14:12:30 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:12:30 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
25/03/09 14:12:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=17 partitionId=0
25/03/09 14:12:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 519604792 nanos, during time span of 523625875 nanos.
25/03/09 14:12:31 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2387 bytes result sent to driver
25/03/09 14:12:31 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:12:31 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 539 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:31 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/03/09 14:12:31 INFO DAGScheduler: ShuffleMapStage 17 (start at NativeMethodAccessorImpl.java:0) finished in 0.541 s
25/03/09 14:12:31 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:12:31 INFO DAGScheduler: running: Set()
25/03/09 14:12:31 INFO DAGScheduler: waiting: Set(ResultStage 18)
25/03/09 14:12:31 INFO DAGScheduler: failed: Set()
25/03/09 14:12:31 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[73] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:31 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:12:31 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:12:31 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:12:31 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[73] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:31 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
25/03/09 14:12:31 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:12:31 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
25/03/09 14:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:12:31 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 3995 bytes result sent to driver
25/03/09 14:12:31 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 7 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:31 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/03/09 14:12:31 INFO DAGScheduler: ResultStage 18 (start at NativeMethodAccessorImpl.java:0) finished in 0.010 s
25/03/09 14:12:31 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
25/03/09 14:12:31 INFO DAGScheduler: Job 13 finished: start at NativeMethodAccessorImpl.java:0, took 0.554933 s
2025-03-09 14:12:31,231 - INFO - Processing batch 35 with 50 records
2025-03-09 14:12:31,231 - INFO - Applying sentiment analysis...
2025-03-09 14:12:31,253 - INFO - DataFrame schema:
2025-03-09 14:12:31,253 - INFO - Sample of processed data:
25/03/09 14:12:31 INFO CodeGenerator: Code generated in 4.386958 ms
25/03/09 14:12:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:31 INFO DAGScheduler: Got job 14 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:31 INFO DAGScheduler: Final stage: ResultStage 19 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:31 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:12:31 INFO DAGScheduler: Missing parents: List()
25/03/09 14:12:31 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[78] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:31 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:12:31 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:12:31 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:12:31 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:31 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[78] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:31 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/03/09 14:12:31 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:12:31 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
25/03/09 14:12:31 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:31 INFO CodeGenerator: Code generated in 6.306625 ms
25/03/09 14:12:31 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=19 partitionId=0
25/03/09 14:12:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 19:>                                                         (0 + 1) / 1]25/03/09 14:12:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 545179959 nanos, during time span of 688454708 nanos.
25/03/09 14:12:32 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3467 bytes result sent to driver
25/03/09 14:12:32 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 711 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:32 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/03/09 14:12:32 INFO DAGScheduler: ResultStage 19 (start at NativeMethodAccessorImpl.java:0) finished in 0.723 s
25/03/09 14:12:32 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/03/09 14:12:32 INFO DAGScheduler: Job 14 finished: start at NativeMethodAccessorImpl.java:0, took 0.726240 s
                                                                                +-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:11:31.309961|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:11:31.309961|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:11:32.766554|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:11:32.766554|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:11:32.766554| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:11:32.766554| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:11:32.766554|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:12:32,033 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:12:32,033 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:12:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:32 INFO DAGScheduler: Registering RDD 80 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 5
25/03/09 14:12:32 INFO DAGScheduler: Got job 15 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:32 INFO DAGScheduler: Final stage: ResultStage 21 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
25/03/09 14:12:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
25/03/09 14:12:32 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[80] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:12:32 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:32 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[80] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:32 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
25/03/09 14:12:32 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:12:32 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:12:32 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
25/03/09 14:12:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=20 partitionId=0
25/03/09 14:12:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 20:>                                                         (0 + 1) / 1]25/03/09 14:12:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:12:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 516563542 nanos, during time span of 524569875 nanos.
25/03/09 14:12:32 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2387 bytes result sent to driver
25/03/09 14:12:32 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 542 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:32 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
25/03/09 14:12:32 INFO DAGScheduler: ShuffleMapStage 20 (start at NativeMethodAccessorImpl.java:0) finished in 0.552 s
25/03/09 14:12:32 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:12:32 INFO DAGScheduler: running: Set()
25/03/09 14:12:32 INFO DAGScheduler: waiting: Set(ResultStage 21)
25/03/09 14:12:32 INFO DAGScheduler: failed: Set()
25/03/09 14:12:32 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[83] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:12:32 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:12:32 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[83] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:32 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
25/03/09 14:12:32 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:12:32 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
25/03/09 14:12:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:12:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:12:32 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 3995 bytes result sent to driver
25/03/09 14:12:32 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 6 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:32 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
25/03/09 14:12:32 INFO DAGScheduler: ResultStage 21 (start at NativeMethodAccessorImpl.java:0) finished in 0.011 s
25/03/09 14:12:32 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
25/03/09 14:12:32 INFO DAGScheduler: Job 15 finished: start at NativeMethodAccessorImpl.java:0, took 0.565668 s
                                                                                2025-03-09 14:12:32,634 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:12:32,634 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:12:32 INFO CodeGenerator: Code generated in 4.078667 ms
25/03/09 14:12:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:32 INFO DAGScheduler: Got job 16 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:32 INFO DAGScheduler: Final stage: ResultStage 22 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:32 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:12:32 INFO DAGScheduler: Missing parents: List()
25/03/09 14:12:32 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[88] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:12:32 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:12:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:12:32 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[88] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:32 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
25/03/09 14:12:32 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:12:32 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
25/03/09 14:12:32 INFO CodeGenerator: Code generated in 4.292417 ms
25/03/09 14:12:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=22 partitionId=0
25/03/09 14:12:32 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:12:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
[Stage 22:>                                                         (0 + 1) / 1]25/03/09 14:12:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:34 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 523709000 nanos, during time span of 2097603625 nanos.
25/03/09 14:12:34 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3994 bytes result sent to driver
25/03/09 14:12:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:34 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 2117 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:34 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
25/03/09 14:12:34 INFO DAGScheduler: ResultStage 22 (start at NativeMethodAccessorImpl.java:0) finished in 2.120 s
25/03/09 14:12:34 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
25/03/09 14:12:34 INFO DAGScheduler: Job 16 finished: start at NativeMethodAccessorImpl.java:0, took 2.125474 s
                                                                                25/03/09 14:12:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:12:34 INFO CodeGenerator: Code generated in 4.124417 ms
25/03/09 14:12:34 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@5714b501,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@27a70fc8). The input RDD has 1 partitions.
25/03/09 14:12:34 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:12:34 INFO DAGScheduler: Got job 17 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:12:34 INFO DAGScheduler: Final stage: ResultStage 23 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:12:34 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:12:34 INFO DAGScheduler: Missing parents: List()
25/03/09 14:12:34 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[92] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:12:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:12:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 2020.3 MiB)
25/03/09 14:12:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.0.201:55761 (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:12:34 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
25/03/09 14:12:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[92] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:12:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
25/03/09 14:12:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:12:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:12:34 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
25/03/09 14:12:34 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5750 untilOffset=5800, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=35 taskId=23 partitionId=0
25/03/09 14:12:34 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:34 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5750 for partition geopolitics_events-0
25/03/09 14:12:34 INFO CodeGenerator: Code generated in 7.64375 ms
25/03/09 14:12:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 23:>                                                         (0 + 1) / 1]25/03/09 14:12:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:12:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5800, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:12:38 INFO PythonUDFRunner: Times: total = 3123, boot = 4, init = 1722, finish = 1397
25/03/09 14:12:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 23, attempt 0, stage 23.0)
25/03/09 14:12:38 INFO DataWritingSparkTask: Committed partition 0 (task 23, attempt 0, stage 23.0)
25/03/09 14:12:38 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 520196292 nanos, during time span of 3215154208 nanos.
25/03/09 14:12:38 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2691 bytes result sent to driver
25/03/09 14:12:38 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 3262 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:12:38 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
25/03/09 14:12:38 INFO DAGScheduler: ResultStage 23 (start at NativeMethodAccessorImpl.java:0) finished in 3.301 s
25/03/09 14:12:38 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:12:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
25/03/09 14:12:38 INFO DAGScheduler: Job 17 finished: start at NativeMethodAccessorImpl.java:0, took 3.303399 s
                                                                                25/03/09 14:12:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@5714b501,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@27a70fc8) is committing.
25/03/09 14:12:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@5714b501,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@27a70fc8) committed.
2025-03-09 14:12:38,171 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:12:38,171 - INFO - Successfully processed batch 35
25/03/09 14:12:38 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/35 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.35.ee8b6dbe-98c4-4f65-9cd5-082dc3782fa9.tmp
25/03/09 14:12:38 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.35.ee8b6dbe-98c4-4f65-9cd5-082dc3782fa9.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/35
25/03/09 14:12:38 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:42:30.004Z",
  "batchId" : 35,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.003200640128025,
  "processedRowsPerSecond" : 19.488428745432397,
  "durationMs" : {
    "addBatch" : 8113,
    "commitOffsets" : 43,
    "getBatch" : 1,
    "latestOffset" : 15,
    "queryPlanning" : 6,
    "triggerExecution" : 8210,
    "walCommit" : 31
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5750
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5800
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5800
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.003200640128025,
    "processedRowsPerSecond" : 19.488428745432397,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:12:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:13:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:13:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:13:30 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/36 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.36.c8697ebf-631e-42d4-93aa-e83e32d907bc.tmp
25/03/09 14:13:30 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.36.c8697ebf-631e-42d4-93aa-e83e32d907bc.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/36
25/03/09 14:13:30 INFO MicroBatchExecution: Committed offsets for batch 36. Metadata OffsetSeqMetadata(0,1741509810012,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:13:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:13:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:13:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:13:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:13:30,076 - INFO - Received command c on object id p0
25/03/09 14:13:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:30 INFO DAGScheduler: Got job 18 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:30 INFO DAGScheduler: Final stage: ResultStage 24 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:30 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:13:30 INFO DAGScheduler: Missing parents: List()
25/03/09 14:13:30 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[99] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:30 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:13:30 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:13:30 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:13:30 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[99] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:30 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
25/03/09 14:13:30 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.0.201:55761 in memory (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:30 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:13:30 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
25/03/09 14:13:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=24 partitionId=0
25/03/09 14:13:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:13:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:30 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 517114125 nanos, during time span of 521989666 nanos.
25/03/09 14:13:30 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1914 bytes result sent to driver
25/03/09 14:13:30 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 532 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:30 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
25/03/09 14:13:30 INFO DAGScheduler: ResultStage 24 (start at NativeMethodAccessorImpl.java:0) finished in 0.541 s
25/03/09 14:13:30 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
25/03/09 14:13:30 INFO DAGScheduler: Job 18 finished: start at NativeMethodAccessorImpl.java:0, took 0.543882 s
25/03/09 14:13:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:30 INFO DAGScheduler: Registering RDD 101 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 6
25/03/09 14:13:30 INFO DAGScheduler: Got job 19 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:30 INFO DAGScheduler: Final stage: ResultStage 26 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
25/03/09 14:13:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
25/03/09 14:13:30 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[101] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:30 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:13:30 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:13:30 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:30 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[101] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:30 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
25/03/09 14:13:30 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:13:30 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
25/03/09 14:13:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=25 partitionId=0
25/03/09 14:13:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 511987667 nanos, during time span of 515840000 nanos.
25/03/09 14:13:31 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2387 bytes result sent to driver
25/03/09 14:13:31 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:13:31 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 538 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:31 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
25/03/09 14:13:31 INFO DAGScheduler: ShuffleMapStage 25 (start at NativeMethodAccessorImpl.java:0) finished in 0.541 s
25/03/09 14:13:31 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:13:31 INFO DAGScheduler: running: Set()
25/03/09 14:13:31 INFO DAGScheduler: waiting: Set(ResultStage 26)
25/03/09 14:13:31 INFO DAGScheduler: failed: Set()
25/03/09 14:13:31 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[104] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:31 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:13:31 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:13:31 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:13:31 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[104] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:31 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
25/03/09 14:13:31 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:13:31 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
25/03/09 14:13:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:13:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:13:31 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 3952 bytes result sent to driver
25/03/09 14:13:31 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:31 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
25/03/09 14:13:31 INFO DAGScheduler: ResultStage 26 (start at NativeMethodAccessorImpl.java:0) finished in 0.007 s
25/03/09 14:13:31 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
25/03/09 14:13:31 INFO DAGScheduler: Job 19 finished: start at NativeMethodAccessorImpl.java:0, took 0.550634 s
2025-03-09 14:13:31,198 - INFO - Processing batch 36 with 50 records
2025-03-09 14:13:31,198 - INFO - Applying sentiment analysis...
2025-03-09 14:13:31,207 - INFO - DataFrame schema:
2025-03-09 14:13:31,207 - INFO - Sample of processed data:
25/03/09 14:13:31 INFO CodeGenerator: Code generated in 4.259709 ms
25/03/09 14:13:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:31 INFO DAGScheduler: Got job 20 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:31 INFO DAGScheduler: Final stage: ResultStage 27 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:31 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:13:31 INFO DAGScheduler: Missing parents: List()
25/03/09 14:13:31 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[109] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:31 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:13:31 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:13:31 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:13:31 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:31 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:13:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[109] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:31 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
25/03/09 14:13:31 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:13:31 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
25/03/09 14:13:31 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:31 INFO CodeGenerator: Code generated in 3.64225 ms
25/03/09 14:13:31 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=27 partitionId=0
25/03/09 14:13:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 27:>                                                         (0 + 1) / 1]25/03/09 14:13:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 549774542 nanos, during time span of 687886459 nanos.
25/03/09 14:13:31 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3467 bytes result sent to driver
25/03/09 14:13:31 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 706 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:31 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
25/03/09 14:13:31 INFO DAGScheduler: ResultStage 27 (start at NativeMethodAccessorImpl.java:0) finished in 0.715 s
25/03/09 14:13:31 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
25/03/09 14:13:31 INFO DAGScheduler: Job 20 finished: start at NativeMethodAccessorImpl.java:0, took 0.718759 s
                                                                                +-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:12:31.257915|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:12:31.257915|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:12:32.641926|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:12:32.641926|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:12:32.641926| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:12:32.641926| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:12:32.641926|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:13:31,998 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:13:31,999 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:13:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:32 INFO DAGScheduler: Registering RDD 111 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 7
25/03/09 14:13:32 INFO DAGScheduler: Got job 21 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:32 INFO DAGScheduler: Final stage: ResultStage 29 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
25/03/09 14:13:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
25/03/09 14:13:32 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:13:32 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:32 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:32 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
25/03/09 14:13:32 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:13:32 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:13:32 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
25/03/09 14:13:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=28 partitionId=0
25/03/09 14:13:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 28:>                                                         (0 + 1) / 1]25/03/09 14:13:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 535501792 nanos, during time span of 539418458 nanos.
25/03/09 14:13:32 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2387 bytes result sent to driver
25/03/09 14:13:32 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 554 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:32 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
25/03/09 14:13:32 INFO DAGScheduler: ShuffleMapStage 28 (start at NativeMethodAccessorImpl.java:0) finished in 0.562 s
25/03/09 14:13:32 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:13:32 INFO DAGScheduler: running: Set()
25/03/09 14:13:32 INFO DAGScheduler: waiting: Set(ResultStage 29)
25/03/09 14:13:32 INFO DAGScheduler: failed: Set()
25/03/09 14:13:32 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[114] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:13:32 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:13:32 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[114] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:32 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
25/03/09 14:13:32 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:13:32 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
25/03/09 14:13:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:13:32 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 3995 bytes result sent to driver
25/03/09 14:13:32 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:32 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
25/03/09 14:13:32 INFO DAGScheduler: ResultStage 29 (start at NativeMethodAccessorImpl.java:0) finished in 0.009 s
25/03/09 14:13:32 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
25/03/09 14:13:32 INFO DAGScheduler: Job 21 finished: start at NativeMethodAccessorImpl.java:0, took 0.574979 s
                                                                                2025-03-09 14:13:32,591 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:13:32,591 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:13:32 INFO CodeGenerator: Code generated in 4.520375 ms
25/03/09 14:13:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:32 INFO DAGScheduler: Got job 22 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:32 INFO DAGScheduler: Final stage: ResultStage 30 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:32 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:13:32 INFO DAGScheduler: Missing parents: List()
25/03/09 14:13:32 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[119] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:13:32 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:13:32 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:13:32 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[119] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:32 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
25/03/09 14:13:32 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:13:32 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
25/03/09 14:13:32 INFO CodeGenerator: Code generated in 3.399666 ms
25/03/09 14:13:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=30 partitionId=0
25/03/09 14:13:32 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 30:>                                                         (0 + 1) / 1]25/03/09 14:13:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:34 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 516254792 nanos, during time span of 2153524750 nanos.
25/03/09 14:13:34 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:13:34 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 4001 bytes result sent to driver
25/03/09 14:13:34 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 2179 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:34 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
25/03/09 14:13:34 INFO DAGScheduler: ResultStage 30 (start at NativeMethodAccessorImpl.java:0) finished in 2.183 s
25/03/09 14:13:34 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
25/03/09 14:13:34 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:34 INFO DAGScheduler: Job 22 finished: start at NativeMethodAccessorImpl.java:0, took 2.187134 s
                                                                                25/03/09 14:13:34 INFO CodeGenerator: Code generated in 5.96875 ms
25/03/09 14:13:34 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@445c92d7,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4f79fb82). The input RDD has 1 partitions.
25/03/09 14:13:34 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:13:34 INFO DAGScheduler: Got job 23 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:13:34 INFO DAGScheduler: Final stage: ResultStage 31 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:13:34 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:13:34 INFO DAGScheduler: Missing parents: List()
25/03/09 14:13:34 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[123] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:13:34 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:13:34 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 2020.3 MiB)
25/03/09 14:13:34 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.0.201:55761 (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:13:34 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
25/03/09 14:13:34 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:13:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[123] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:13:34 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
25/03/09 14:13:34 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:13:34 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
25/03/09 14:13:34 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5800 untilOffset=5850, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=36 taskId=31 partitionId=0
25/03/09 14:13:34 INFO CodeGenerator: Code generated in 4.667583 ms
25/03/09 14:13:34 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:34 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5800 for partition geopolitics_events-0
25/03/09 14:13:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 31:>                                                         (0 + 1) / 1]25/03/09 14:13:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:13:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5850, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:13:38 INFO PythonUDFRunner: Times: total = 3341, boot = 8, init = 1926, finish = 1407
25/03/09 14:13:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 31, attempt 0, stage 31.0)
25/03/09 14:13:38 INFO DataWritingSparkTask: Committed partition 0 (task 31, attempt 0, stage 31.0)
25/03/09 14:13:38 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 567227834 nanos, during time span of 3413476375 nanos.
25/03/09 14:13:38 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2691 bytes result sent to driver
25/03/09 14:13:38 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 3449 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:13:38 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
25/03/09 14:13:38 INFO DAGScheduler: ResultStage 31 (start at NativeMethodAccessorImpl.java:0) finished in 3.459 s
25/03/09 14:13:38 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:13:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
25/03/09 14:13:38 INFO DAGScheduler: Job 23 finished: start at NativeMethodAccessorImpl.java:0, took 3.462143 s
                                                                                25/03/09 14:13:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@445c92d7,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4f79fb82) is committing.
25/03/09 14:13:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@445c92d7,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4f79fb82) committed.
2025-03-09 14:13:38,345 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:13:38,345 - INFO - Successfully processed batch 36
25/03/09 14:13:38 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/36 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.36.20fc1abe-d7b0-4eed-88f1-fc5abda447cb.tmp
25/03/09 14:13:38 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.36.20fc1abe-d7b0-4eed-88f1-fc5abda447cb.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/36
25/03/09 14:13:38 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:43:30.005Z",
  "batchId" : 36,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 15.99360255897641,
  "processedRowsPerSecond" : 19.0976366674624,
  "durationMs" : {
    "addBatch" : 8282,
    "commitOffsets" : 38,
    "getBatch" : 0,
    "latestOffset" : 7,
    "queryPlanning" : 6,
    "triggerExecution" : 8378,
    "walCommit" : 44
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5800
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5850
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5850
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 15.99360255897641,
    "processedRowsPerSecond" : 19.0976366674624,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:13:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:14:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:14:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:14:30 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/37 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.37.8ec4b0e8-f931-4479-a59a-09d0408c1d69.tmp
25/03/09 14:14:30 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.37.8ec4b0e8-f931-4479-a59a-09d0408c1d69.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/37
25/03/09 14:14:30 INFO MicroBatchExecution: Committed offsets for batch 37. Metadata OffsetSeqMetadata(0,1741509870018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:14:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:14:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:14:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:14:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:14:30,058 - INFO - Received command c on object id p0
25/03/09 14:14:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:30 INFO DAGScheduler: Got job 24 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:30 INFO DAGScheduler: Final stage: ResultStage 32 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:30 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:14:30 INFO DAGScheduler: Missing parents: List()
25/03/09 14:14:30 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[130] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:30 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:14:30 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:14:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:14:30 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[130] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:30 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
25/03/09 14:14:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 192.168.0.201:55761 in memory (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:14:30 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:14:30 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
25/03/09 14:14:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=32 partitionId=0
25/03/09 14:14:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:30 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 547897125 nanos, during time span of 552895625 nanos.
25/03/09 14:14:30 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 1914 bytes result sent to driver
25/03/09 14:14:30 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 568 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:30 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
25/03/09 14:14:30 INFO DAGScheduler: ResultStage 32 (start at NativeMethodAccessorImpl.java:0) finished in 0.586 s
25/03/09 14:14:30 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
25/03/09 14:14:30 INFO DAGScheduler: Job 24 finished: start at NativeMethodAccessorImpl.java:0, took 0.587932 s
25/03/09 14:14:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:30 INFO DAGScheduler: Registering RDD 132 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 8
25/03/09 14:14:30 INFO DAGScheduler: Got job 25 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:30 INFO DAGScheduler: Final stage: ResultStage 34 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
25/03/09 14:14:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
25/03/09 14:14:30 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:30 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:14:30 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:14:30 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:14:30 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:30 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
25/03/09 14:14:30 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:14:30 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
25/03/09 14:14:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=33 partitionId=0
25/03/09 14:14:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 516988667 nanos, during time span of 520382083 nanos.
25/03/09 14:14:31 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 2387 bytes result sent to driver
25/03/09 14:14:31 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:14:31 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 545 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:31 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
25/03/09 14:14:31 INFO DAGScheduler: ShuffleMapStage 33 (start at NativeMethodAccessorImpl.java:0) finished in 0.548 s
25/03/09 14:14:31 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:14:31 INFO DAGScheduler: running: Set()
25/03/09 14:14:31 INFO DAGScheduler: waiting: Set(ResultStage 34)
25/03/09 14:14:31 INFO DAGScheduler: failed: Set()
25/03/09 14:14:31 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[135] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:31 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:14:31 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:14:31 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:14:31 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[135] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:31 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
25/03/09 14:14:31 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:14:31 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
25/03/09 14:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:14:31 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 3995 bytes result sent to driver
25/03/09 14:14:31 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:31 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
25/03/09 14:14:31 INFO DAGScheduler: ResultStage 34 (start at NativeMethodAccessorImpl.java:0) finished in 0.005 s
25/03/09 14:14:31 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
25/03/09 14:14:31 INFO DAGScheduler: Job 25 finished: start at NativeMethodAccessorImpl.java:0, took 0.556651 s
2025-03-09 14:14:31,223 - INFO - Processing batch 37 with 50 records
2025-03-09 14:14:31,223 - INFO - Applying sentiment analysis...
2025-03-09 14:14:31,232 - INFO - DataFrame schema:
2025-03-09 14:14:31,232 - INFO - Sample of processed data:
25/03/09 14:14:31 INFO CodeGenerator: Code generated in 3.509917 ms
25/03/09 14:14:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:31 INFO DAGScheduler: Got job 26 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:31 INFO DAGScheduler: Final stage: ResultStage 35 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:31 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:14:31 INFO DAGScheduler: Missing parents: List()
25/03/09 14:14:31 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[140] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:31 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:14:31 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:14:31 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:14:31 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[140] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:31 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
25/03/09 14:14:31 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:14:31 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
25/03/09 14:14:31 INFO CodeGenerator: Code generated in 3.484458 ms
25/03/09 14:14:31 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=35 partitionId=0
25/03/09 14:14:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 514297834 nanos, during time span of 666856917 nanos.
25/03/09 14:14:31 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 3463 bytes result sent to driver
25/03/09 14:14:31 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 680 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:31 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
25/03/09 14:14:31 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:14:31 INFO DAGScheduler: ResultStage 35 (start at NativeMethodAccessorImpl.java:0) finished in 0.683 s
25/03/09 14:14:31 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
25/03/09 14:14:31 INFO DAGScheduler: Job 26 finished: start at NativeMethodAccessorImpl.java:0, took 0.687135 s
25/03/09 14:14:31 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:13:31.225167|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:13:31.225167|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at             |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:13:32.59625|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:13:32.59625|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:13:32.59625| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:13:32.59625| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:13:32.59625|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:14:31,972 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:14:31,972 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:14:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:32 INFO DAGScheduler: Registering RDD 142 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 9
25/03/09 14:14:32 INFO DAGScheduler: Got job 27 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:32 INFO DAGScheduler: Final stage: ResultStage 37 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
25/03/09 14:14:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
25/03/09 14:14:32 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[142] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:14:32 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:14:32 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[142] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:32 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
25/03/09 14:14:32 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:14:32 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:14:32 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
25/03/09 14:14:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=36 partitionId=0
25/03/09 14:14:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 526475625 nanos, during time span of 529642208 nanos.
[Stage 36:>                                                         (0 + 1) / 1]25/03/09 14:14:32 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 2387 bytes result sent to driver
25/03/09 14:14:32 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 542 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:32 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
25/03/09 14:14:32 INFO DAGScheduler: ShuffleMapStage 36 (start at NativeMethodAccessorImpl.java:0) finished in 0.552 s
25/03/09 14:14:32 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:14:32 INFO DAGScheduler: running: Set()
25/03/09 14:14:32 INFO DAGScheduler: waiting: Set(ResultStage 37)
25/03/09 14:14:32 INFO DAGScheduler: failed: Set()
25/03/09 14:14:32 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[145] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:14:32 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:14:32 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[145] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:32 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
25/03/09 14:14:32 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:14:32 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
25/03/09 14:14:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:14:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:14:32 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 3952 bytes result sent to driver
25/03/09 14:14:32 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:32 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
25/03/09 14:14:32 INFO DAGScheduler: ResultStage 37 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:14:32 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
25/03/09 14:14:32 INFO DAGScheduler: Job 27 finished: start at NativeMethodAccessorImpl.java:0, took 0.560741 s
                                                                                2025-03-09 14:14:32,570 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:14:32,570 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:14:32 INFO CodeGenerator: Code generated in 18.046167 ms
25/03/09 14:14:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:32 INFO DAGScheduler: Got job 28 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:32 INFO DAGScheduler: Final stage: ResultStage 38 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:32 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:14:32 INFO DAGScheduler: Missing parents: List()
25/03/09 14:14:32 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[150] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:14:32 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:14:32 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:14:32 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[150] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:32 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
25/03/09 14:14:32 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:14:32 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
25/03/09 14:14:32 INFO CodeGenerator: Code generated in 3.868666 ms
25/03/09 14:14:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=38 partitionId=0
25/03/09 14:14:32 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 38:>                                                         (0 + 1) / 1]25/03/09 14:14:34 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 514977666 nanos, during time span of 2220218333 nanos.
25/03/09 14:14:34 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 4001 bytes result sent to driver
25/03/09 14:14:34 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:14:34 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 2240 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:34 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
25/03/09 14:14:34 INFO DAGScheduler: ResultStage 38 (start at NativeMethodAccessorImpl.java:0) finished in 2.245 s
25/03/09 14:14:34 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
25/03/09 14:14:34 INFO DAGScheduler: Job 28 finished: start at NativeMethodAccessorImpl.java:0, took 2.250080 s
                                                                                25/03/09 14:14:34 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:14:34 INFO CodeGenerator: Code generated in 3.332292 ms
25/03/09 14:14:34 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@2e8a1033,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2be19523). The input RDD has 1 partitions.
25/03/09 14:14:34 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:14:34 INFO DAGScheduler: Got job 29 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:14:34 INFO DAGScheduler: Final stage: ResultStage 39 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:14:34 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:14:34 INFO DAGScheduler: Missing parents: List()
25/03/09 14:14:34 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[154] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:14:34 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:14:34 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 2020.3 MiB)
25/03/09 14:14:34 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 192.168.0.201:55761 (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:14:34 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
25/03/09 14:14:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[154] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:14:34 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
25/03/09 14:14:34 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:14:34 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:14:34 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
25/03/09 14:14:34 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5850 untilOffset=5900, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=37 taskId=39 partitionId=0
25/03/09 14:14:34 INFO CodeGenerator: Code generated in 4.150375 ms
25/03/09 14:14:34 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:34 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5850 for partition geopolitics_events-0
25/03/09 14:14:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:14:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:14:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5900, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:14:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 39:>                                                         (0 + 1) / 1]25/03/09 14:14:38 INFO PythonUDFRunner: Times: total = 3641, boot = 5, init = 1968, finish = 1668
25/03/09 14:14:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 39, attempt 0, stage 39.0)
25/03/09 14:14:38 INFO DataWritingSparkTask: Committed partition 0 (task 39, attempt 0, stage 39.0)
25/03/09 14:14:38 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 549910709 nanos, during time span of 3723520709 nanos.
25/03/09 14:14:38 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 2691 bytes result sent to driver
25/03/09 14:14:38 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 3754 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:14:38 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
25/03/09 14:14:38 INFO DAGScheduler: ResultStage 39 (start at NativeMethodAccessorImpl.java:0) finished in 3.765 s
25/03/09 14:14:38 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:14:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
25/03/09 14:14:38 INFO DAGScheduler: Job 29 finished: start at NativeMethodAccessorImpl.java:0, took 3.767348 s
                                                                                25/03/09 14:14:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@2e8a1033,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2be19523) is committing.
25/03/09 14:14:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@2e8a1033,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2be19523) committed.
2025-03-09 14:14:38,697 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:14:38,697 - INFO - Successfully processed batch 37
25/03/09 14:14:38 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/37 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.37.639c8412-3e2c-4da0-8f72-58e97feacab5.tmp
25/03/09 14:14:38 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.37.639c8412-3e2c-4da0-8f72-58e97feacab5.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/37
25/03/09 14:14:38 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:44:30.005Z",
  "batchId" : 37,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 15.992003998000998,
  "processedRowsPerSecond" : 18.31082627603571,
  "durationMs" : {
    "addBatch" : 8648,
    "commitOffsets" : 45,
    "getBatch" : 0,
    "latestOffset" : 13,
    "queryPlanning" : 6,
    "triggerExecution" : 8738,
    "walCommit" : 24
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5850
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5900
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5900
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 15.992003998000998,
    "processedRowsPerSecond" : 18.31082627603571,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:14:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:15:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:15:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:15:30 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/38 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.38.d21d7a25-adec-4cba-a0ba-fc2d92b8eed9.tmp
25/03/09 14:15:30 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.38.d21d7a25-adec-4cba-a0ba-fc2d92b8eed9.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/38
25/03/09 14:15:30 INFO MicroBatchExecution: Committed offsets for batch 38. Metadata OffsetSeqMetadata(0,1741509930015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:15:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:15:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:15:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:15:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:15:30,056 - INFO - Received command c on object id p0
25/03/09 14:15:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:30 INFO DAGScheduler: Got job 30 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:30 INFO DAGScheduler: Final stage: ResultStage 40 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:30 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:15:30 INFO DAGScheduler: Missing parents: List()
25/03/09 14:15:30 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[161] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:30 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:15:30 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:15:30 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:15:30 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 192.168.0.201:55761 in memory (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:15:30 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[161] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:30 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
25/03/09 14:15:30 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:15:30 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
25/03/09 14:15:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=40 partitionId=0
25/03/09 14:15:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:15:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:30 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 558743292 nanos, during time span of 567842166 nanos.
25/03/09 14:15:30 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 1914 bytes result sent to driver
25/03/09 14:15:30 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 579 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:30 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
25/03/09 14:15:30 INFO DAGScheduler: ResultStage 40 (start at NativeMethodAccessorImpl.java:0) finished in 0.586 s
25/03/09 14:15:30 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
25/03/09 14:15:30 INFO DAGScheduler: Job 30 finished: start at NativeMethodAccessorImpl.java:0, took 0.589379 s
25/03/09 14:15:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:30 INFO DAGScheduler: Registering RDD 163 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 10
25/03/09 14:15:30 INFO DAGScheduler: Got job 31 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:30 INFO DAGScheduler: Final stage: ResultStage 42 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
25/03/09 14:15:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
25/03/09 14:15:30 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[163] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:30 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:15:30 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:15:30 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:15:30 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[163] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:30 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
25/03/09 14:15:30 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:15:30 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
25/03/09 14:15:30 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=41 partitionId=0
25/03/09 14:15:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:31 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 532476875 nanos, during time span of 535538833 nanos.
25/03/09 14:15:31 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 2387 bytes result sent to driver
25/03/09 14:15:31 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:15:31 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 564 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
25/03/09 14:15:31 INFO DAGScheduler: ShuffleMapStage 41 (start at NativeMethodAccessorImpl.java:0) finished in 0.570 s
25/03/09 14:15:31 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:15:31 INFO DAGScheduler: running: Set()
25/03/09 14:15:31 INFO DAGScheduler: waiting: Set(ResultStage 42)
25/03/09 14:15:31 INFO DAGScheduler: failed: Set()
25/03/09 14:15:31 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[166] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:31 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:15:31 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:15:31 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:15:31 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[166] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:31 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
25/03/09 14:15:31 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:15:31 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)
25/03/09 14:15:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:15:31 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 3995 bytes result sent to driver
25/03/09 14:15:31 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 5 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
25/03/09 14:15:31 INFO DAGScheduler: ResultStage 42 (start at NativeMethodAccessorImpl.java:0) finished in 0.008 s
25/03/09 14:15:31 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
25/03/09 14:15:31 INFO DAGScheduler: Job 31 finished: start at NativeMethodAccessorImpl.java:0, took 0.581474 s
2025-03-09 14:15:31,255 - INFO - Processing batch 38 with 50 records
2025-03-09 14:15:31,256 - INFO - Applying sentiment analysis...
2025-03-09 14:15:31,267 - INFO - DataFrame schema:
2025-03-09 14:15:31,268 - INFO - Sample of processed data:
25/03/09 14:15:31 INFO CodeGenerator: Code generated in 4.261125 ms
25/03/09 14:15:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:31 INFO DAGScheduler: Got job 32 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:31 INFO DAGScheduler: Final stage: ResultStage 43 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:31 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:15:31 INFO DAGScheduler: Missing parents: List()
25/03/09 14:15:31 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[171] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:31 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:15:31 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:15:31 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:15:31 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:31 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:15:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[171] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:31 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
25/03/09 14:15:31 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:15:31 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)
25/03/09 14:15:31 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:15:31 INFO CodeGenerator: Code generated in 4.314708 ms
25/03/09 14:15:31 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=43 partitionId=0
25/03/09 14:15:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:31 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 43:>                                                         (0 + 1) / 1]25/03/09 14:15:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 520279791 nanos, during time span of 673499167 nanos.
25/03/09 14:15:32 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 3467 bytes result sent to driver
25/03/09 14:15:32 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 692 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:32 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
25/03/09 14:15:32 INFO DAGScheduler: ResultStage 43 (start at NativeMethodAccessorImpl.java:0) finished in 0.704 s
25/03/09 14:15:32 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
25/03/09 14:15:32 INFO DAGScheduler: Job 32 finished: start at NativeMethodAccessorImpl.java:0, took 0.707487 s
                                                                                +-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:14:31.245548|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:14:31.245548|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at             |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:14:32.57561|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:14:32.57561|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:14:32.57561| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:14:32.57561| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:14:32.57561|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+-------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:15:32,056 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:15:32,057 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:15:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:32 INFO DAGScheduler: Registering RDD 173 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 11
25/03/09 14:15:32 INFO DAGScheduler: Got job 33 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:32 INFO DAGScheduler: Final stage: ResultStage 45 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
25/03/09 14:15:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
25/03/09 14:15:32 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[173] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:15:32 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:15:32 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:15:32 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[173] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:32 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
25/03/09 14:15:32 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:15:32 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)
25/03/09 14:15:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=44 partitionId=0
25/03/09 14:15:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:15:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:32 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 520740167 nanos, during time span of 524438292 nanos.
25/03/09 14:15:32 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 2387 bytes result sent to driver
25/03/09 14:15:32 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 537 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:32 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
25/03/09 14:15:32 INFO DAGScheduler: ShuffleMapStage 44 (start at NativeMethodAccessorImpl.java:0) finished in 0.547 s
25/03/09 14:15:32 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:15:32 INFO DAGScheduler: running: Set()
25/03/09 14:15:32 INFO DAGScheduler: waiting: Set(ResultStage 45)
25/03/09 14:15:32 INFO DAGScheduler: failed: Set()
25/03/09 14:15:32 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[176] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:15:32 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:15:32 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[176] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:32 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
25/03/09 14:15:32 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:15:32 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
25/03/09 14:15:32 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:15:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:15:32 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 3995 bytes result sent to driver
25/03/09 14:15:32 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:32 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
25/03/09 14:15:32 INFO DAGScheduler: ResultStage 45 (start at NativeMethodAccessorImpl.java:0) finished in 0.007 s
25/03/09 14:15:32 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
25/03/09 14:15:32 INFO DAGScheduler: Job 33 finished: start at NativeMethodAccessorImpl.java:0, took 0.555162 s
2025-03-09 14:15:32,632 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:15:32,632 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:15:32 INFO CodeGenerator: Code generated in 3.007542 ms
25/03/09 14:15:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:32 INFO DAGScheduler: Got job 34 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:32 INFO DAGScheduler: Final stage: ResultStage 46 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:32 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:15:32 INFO DAGScheduler: Missing parents: List()
25/03/09 14:15:32 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[181] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:15:32 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:15:32 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:15:32 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[181] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:32 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
25/03/09 14:15:32 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:15:32 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)
25/03/09 14:15:32 INFO CodeGenerator: Code generated in 4.019625 ms
25/03/09 14:15:32 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=46 partitionId=0
25/03/09 14:15:32 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:15:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:33 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 46:>                                                         (0 + 1) / 1]25/03/09 14:15:33 INFO NetworkClient: [AdminClient clientId=adminclient-1] Node -1 disconnected.
25/03/09 14:15:34 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 528142125 nanos, during time span of 2282625583 nanos.
25/03/09 14:15:34 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:15:34 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 3994 bytes result sent to driver
25/03/09 14:15:34 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 2301 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:34 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
25/03/09 14:15:34 INFO DAGScheduler: ResultStage 46 (start at NativeMethodAccessorImpl.java:0) finished in 2.303 s
25/03/09 14:15:34 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
25/03/09 14:15:34 INFO DAGScheduler: Job 34 finished: start at NativeMethodAccessorImpl.java:0, took 2.307610 s
                                                                                25/03/09 14:15:34 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:15:35 INFO CodeGenerator: Code generated in 5.268584 ms
25/03/09 14:15:35 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@200aa66d,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@1d6d46c1). The input RDD has 1 partitions.
25/03/09 14:15:35 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:15:35 INFO DAGScheduler: Got job 35 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:15:35 INFO DAGScheduler: Final stage: ResultStage 47 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:15:35 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:15:35 INFO DAGScheduler: Missing parents: List()
25/03/09 14:15:35 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[185] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:15:35 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:15:35 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.3 MiB)
25/03/09 14:15:35 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 192.168.0.201:55761 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:15:35 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
25/03/09 14:15:35 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:15:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[185] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:15:35 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
25/03/09 14:15:35 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:15:35 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)
25/03/09 14:15:35 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5900 untilOffset=5950, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=38 taskId=47 partitionId=0
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5900 for partition geopolitics_events-0
25/03/09 14:15:35 INFO CodeGenerator: Code generated in 10.997291 ms
25/03/09 14:15:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 47:>                                                         (0 + 1) / 1]25/03/09 14:15:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:15:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=5950, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:35 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:15:38 INFO PythonUDFRunner: Times: total = 3323, boot = 6, init = 1793, finish = 1524
25/03/09 14:15:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 47, attempt 0, stage 47.0)
25/03/09 14:15:38 INFO DataWritingSparkTask: Committed partition 0 (task 47, attempt 0, stage 47.0)
25/03/09 14:15:38 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 519770709 nanos, during time span of 3423637625 nanos.
25/03/09 14:15:38 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 2691 bytes result sent to driver
25/03/09 14:15:38 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 3445 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:15:38 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
25/03/09 14:15:38 INFO DAGScheduler: ResultStage 47 (start at NativeMethodAccessorImpl.java:0) finished in 3.464 s
25/03/09 14:15:38 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:15:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
25/03/09 14:15:38 INFO DAGScheduler: Job 35 finished: start at NativeMethodAccessorImpl.java:0, took 3.468315 s
                                                                                25/03/09 14:15:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@200aa66d,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@1d6d46c1) is committing.
25/03/09 14:15:38 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@200aa66d,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@1d6d46c1) committed.
2025-03-09 14:15:38,505 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:15:38,505 - INFO - Successfully processed batch 38
25/03/09 14:15:38 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/38 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.38.f68c4a7b-76a8-4a24-973a-3905f1a3ab75.tmp
25/03/09 14:15:38 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.38.f68c4a7b-76a8-4a24-973a-3905f1a3ab75.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/38
25/03/09 14:15:38 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:45:30.006Z",
  "batchId" : 38,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 15.99360255897641,
  "processedRowsPerSecond" : 18.71563925605334,
  "durationMs" : {
    "addBatch" : 8458,
    "commitOffsets" : 49,
    "getBatch" : 0,
    "latestOffset" : 9,
    "queryPlanning" : 5,
    "triggerExecution" : 8549,
    "walCommit" : 27
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5900
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 5950
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 5950
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 15.99360255897641,
    "processedRowsPerSecond" : 18.71563925605334,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:15:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:16:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:16:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:16:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:16:38 INFO CassandraConnector: Disconnected from Cassandra cluster.
25/03/09 14:16:40 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/39 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.39.ab214e19-3c51-422b-badc-7d9cd0d76f2a.tmp
25/03/09 14:16:40 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.39.ab214e19-3c51-422b-badc-7d9cd0d76f2a.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/39
25/03/09 14:16:40 INFO MicroBatchExecution: Committed offsets for batch 39. Metadata OffsetSeqMetadata(0,1741510000024,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:16:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:16:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:16:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:16:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:16:40,061 - INFO - Received command c on object id p0
25/03/09 14:16:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:40 INFO DAGScheduler: Got job 36 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:40 INFO DAGScheduler: Final stage: ResultStage 48 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:40 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:16:40 INFO DAGScheduler: Missing parents: List()
25/03/09 14:16:40 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[192] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:40 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:16:40 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:16:40 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 192.168.0.201:55761 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:16:40 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:40 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 192.168.0.201:55761 in memory (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:16:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[192] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:40 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
25/03/09 14:16:40 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:16:40 INFO Executor: Running task 0.0 in stage 48.0 (TID 48)
25/03/09 14:16:40 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=48 partitionId=0
25/03/09 14:16:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 48:>                                                         (0 + 1) / 1]25/03/09 14:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:40 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 528114667 nanos, during time span of 532448000 nanos.
25/03/09 14:16:40 INFO Executor: Finished task 0.0 in stage 48.0 (TID 48). 1914 bytes result sent to driver
25/03/09 14:16:40 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 540 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:40 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
25/03/09 14:16:40 INFO DAGScheduler: ResultStage 48 (start at NativeMethodAccessorImpl.java:0) finished in 0.546 s
25/03/09 14:16:40 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
25/03/09 14:16:40 INFO DAGScheduler: Job 36 finished: start at NativeMethodAccessorImpl.java:0, took 0.548956 s
                                                                                25/03/09 14:16:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:40 INFO DAGScheduler: Registering RDD 194 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 12
25/03/09 14:16:40 INFO DAGScheduler: Got job 37 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:40 INFO DAGScheduler: Final stage: ResultStage 50 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
25/03/09 14:16:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
25/03/09 14:16:40 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[194] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:40 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:16:40 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:16:40 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:16:40 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[194] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:40 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
25/03/09 14:16:40 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:16:40 INFO Executor: Running task 0.0 in stage 49.0 (TID 49)
25/03/09 14:16:40 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=49 partitionId=0
25/03/09 14:16:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:41 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 530521625 nanos, during time span of 533276167 nanos.
25/03/09 14:16:41 INFO Executor: Finished task 0.0 in stage 49.0 (TID 49). 2387 bytes result sent to driver
25/03/09 14:16:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 192.168.0.201:55761 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:16:41 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 544 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:41 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
25/03/09 14:16:41 INFO DAGScheduler: ShuffleMapStage 49 (start at NativeMethodAccessorImpl.java:0) finished in 0.546 s
25/03/09 14:16:41 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:16:41 INFO DAGScheduler: running: Set()
25/03/09 14:16:41 INFO DAGScheduler: waiting: Set(ResultStage 50)
25/03/09 14:16:41 INFO DAGScheduler: failed: Set()
25/03/09 14:16:41 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[197] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:16:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:16:41 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[197] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:41 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
25/03/09 14:16:41 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:16:41 INFO Executor: Running task 0.0 in stage 50.0 (TID 50)
25/03/09 14:16:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:16:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:16:41 INFO Executor: Finished task 0.0 in stage 50.0 (TID 50). 3952 bytes result sent to driver
25/03/09 14:16:41 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:41 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
25/03/09 14:16:41 INFO DAGScheduler: ResultStage 50 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:16:41 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
25/03/09 14:16:41 INFO DAGScheduler: Job 37 finished: start at NativeMethodAccessorImpl.java:0, took 0.554574 s
2025-03-09 14:16:41,184 - INFO - Processing batch 39 with 50 records
2025-03-09 14:16:41,184 - INFO - Applying sentiment analysis...
2025-03-09 14:16:41,191 - INFO - DataFrame schema:
2025-03-09 14:16:41,192 - INFO - Sample of processed data:
25/03/09 14:16:41 INFO CodeGenerator: Code generated in 2.892041 ms
25/03/09 14:16:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:41 INFO DAGScheduler: Got job 38 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:41 INFO DAGScheduler: Final stage: ResultStage 51 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:41 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:16:41 INFO DAGScheduler: Missing parents: List()
25/03/09 14:16:41 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[202] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:16:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:16:41 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[202] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:41 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
25/03/09 14:16:41 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:16:41 INFO Executor: Running task 0.0 in stage 51.0 (TID 51)
25/03/09 14:16:41 INFO CodeGenerator: Code generated in 2.899125 ms
25/03/09 14:16:41 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=51 partitionId=0
25/03/09 14:16:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:41 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:41 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 51:>                                                         (0 + 1) / 1]25/03/09 14:16:41 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 524172625 nanos, during time span of 663608416 nanos.
25/03/09 14:16:41 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:16:41 INFO Executor: Finished task 0.0 in stage 51.0 (TID 51). 3463 bytes result sent to driver
25/03/09 14:16:41 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 677 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:41 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
25/03/09 14:16:41 INFO DAGScheduler: ResultStage 51 (start at NativeMethodAccessorImpl.java:0) finished in 0.680 s
25/03/09 14:16:41 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
25/03/09 14:16:41 INFO DAGScheduler: Job 38 finished: start at NativeMethodAccessorImpl.java:0, took 0.683247 s
                                                                                25/03/09 14:16:41 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:15:31.284649|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:15:31.284649|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:15:32.638444|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:15:32.638444|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:15:32.638444| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:15:32.638444| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:15:32.638444|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:16:41,941 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:16:41,942 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:16:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:41 INFO DAGScheduler: Registering RDD 204 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 13
25/03/09 14:16:41 INFO DAGScheduler: Got job 39 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:41 INFO DAGScheduler: Final stage: ResultStage 53 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
25/03/09 14:16:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
25/03/09 14:16:41 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[204] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:16:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:16:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 192.168.0.201:55761 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:16:41 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[204] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:41 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
25/03/09 14:16:41 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:16:41 INFO Executor: Running task 0.0 in stage 52.0 (TID 52)
25/03/09 14:16:42 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=52 partitionId=0
25/03/09 14:16:42 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:16:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:16:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:42 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 525727708 nanos, during time span of 528674250 nanos.
25/03/09 14:16:42 INFO Executor: Finished task 0.0 in stage 52.0 (TID 52). 2387 bytes result sent to driver
25/03/09 14:16:42 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 548 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:42 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
25/03/09 14:16:42 INFO DAGScheduler: ShuffleMapStage 52 (start at NativeMethodAccessorImpl.java:0) finished in 0.578 s
25/03/09 14:16:42 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:16:42 INFO DAGScheduler: running: Set()
25/03/09 14:16:42 INFO DAGScheduler: waiting: Set(ResultStage 53)
25/03/09 14:16:42 INFO DAGScheduler: failed: Set()
25/03/09 14:16:42 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[207] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:42 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:16:42 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:16:42 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 192.168.0.201:55761 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:16:42 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[207] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:42 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
25/03/09 14:16:42 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:16:42 INFO Executor: Running task 0.0 in stage 53.0 (TID 53)
25/03/09 14:16:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:16:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:16:42 INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 3952 bytes result sent to driver
25/03/09 14:16:42 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:42 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
25/03/09 14:16:42 INFO DAGScheduler: ResultStage 53 (start at NativeMethodAccessorImpl.java:0) finished in 0.005 s
25/03/09 14:16:42 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
25/03/09 14:16:42 INFO DAGScheduler: Job 39 finished: start at NativeMethodAccessorImpl.java:0, took 0.587310 s
2025-03-09 14:16:42,548 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:16:42,548 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:16:42 INFO CodeGenerator: Code generated in 3.361667 ms
25/03/09 14:16:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:42 INFO DAGScheduler: Got job 40 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:42 INFO DAGScheduler: Final stage: ResultStage 54 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:42 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:16:42 INFO DAGScheduler: Missing parents: List()
25/03/09 14:16:42 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[212] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:42 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:16:42 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:16:42 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 192.168.0.201:55761 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:16:42 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[212] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:42 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
25/03/09 14:16:42 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:16:42 INFO Executor: Running task 0.0 in stage 54.0 (TID 54)
25/03/09 14:16:42 INFO CodeGenerator: Code generated in 4.000042 ms
25/03/09 14:16:42 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=54 partitionId=0
25/03/09 14:16:42 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:16:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:43 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 54:>                                                         (0 + 1) / 1]25/03/09 14:16:44 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 516766625 nanos, during time span of 2165293917 nanos.
25/03/09 14:16:44 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 192.168.0.201:55761 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:16:44 INFO Executor: Finished task 0.0 in stage 54.0 (TID 54). 3994 bytes result sent to driver
25/03/09 14:16:44 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 2183 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:44 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
25/03/09 14:16:44 INFO DAGScheduler: ResultStage 54 (start at NativeMethodAccessorImpl.java:0) finished in 2.186 s
25/03/09 14:16:44 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
25/03/09 14:16:44 INFO DAGScheduler: Job 40 finished: start at NativeMethodAccessorImpl.java:0, took 2.188854 s
                                                                                25/03/09 14:16:44 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 192.168.0.201:55761 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:16:44 INFO ContactPoints: Contact point localhost:9042 resolves to multiple addresses, will use them all ([localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1])
25/03/09 14:16:44 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:16:44 INFO CassandraConnector: Connected to Cassandra cluster.
25/03/09 14:16:44 INFO CodeGenerator: Code generated in 2.951458 ms
25/03/09 14:16:44 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@6f1f1461,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b48bda6). The input RDD has 1 partitions.
25/03/09 14:16:44 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:16:44 INFO DAGScheduler: Got job 41 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:16:44 INFO DAGScheduler: Final stage: ResultStage 55 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:16:44 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:16:44 INFO DAGScheduler: Missing parents: List()
25/03/09 14:16:44 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:16:44 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:16:44 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 2020.3 MiB)
25/03/09 14:16:44 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 192.168.0.201:55761 (size: 23.3 KiB, free: 2020.4 MiB)
25/03/09 14:16:44 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 192.168.0.201:55761 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:16:44 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585
25/03/09 14:16:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:16:44 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
25/03/09 14:16:44 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:16:44 INFO Executor: Running task 0.0 in stage 55.0 (TID 55)
25/03/09 14:16:45 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=5950 untilOffset=6000, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=39 taskId=55 partitionId=0
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to offset 5950 for partition geopolitics_events-0
25/03/09 14:16:45 INFO CodeGenerator: Code generated in 5.115042 ms
25/03/09 14:16:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 55:>                                                         (0 + 1) / 1]25/03/09 14:16:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:16:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=6000, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:45 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:16:48 INFO PythonUDFRunner: Times: total = 3532, boot = 106, init = 1747, finish = 1679
25/03/09 14:16:48 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 55, attempt 0, stage 55.0)
25/03/09 14:16:48 INFO DataWritingSparkTask: Committed partition 0 (task 55, attempt 0, stage 55.0)
25/03/09 14:16:48 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 515077333 nanos, during time span of 3455249541 nanos.
25/03/09 14:16:48 INFO Executor: Finished task 0.0 in stage 55.0 (TID 55). 2691 bytes result sent to driver
25/03/09 14:16:48 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 3578 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:16:48 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
25/03/09 14:16:48 INFO DAGScheduler: ResultStage 55 (start at NativeMethodAccessorImpl.java:0) finished in 3.590 s
25/03/09 14:16:48 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:16:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
25/03/09 14:16:48 INFO DAGScheduler: Job 41 finished: start at NativeMethodAccessorImpl.java:0, took 3.591655 s
                                                                                25/03/09 14:16:48 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@6f1f1461,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b48bda6) is committing.
25/03/09 14:16:48 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@ec0a147,com.datastax.spark.connector.cql.CassandraConnector@6f1f1461,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@4b48bda6) committed.
2025-03-09 14:16:48,491 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:16:48,491 - INFO - Successfully processed batch 39
25/03/09 14:16:48 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/39 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.39.3afe049b-3811-4f13-9ebb-6707b8bb5e84.tmp
25/03/09 14:16:48 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.39.3afe049b-3811-4f13-9ebb-6707b8bb5e84.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/39
25/03/09 14:16:48 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "cfa692d0-1274-437d-bbea-855da0f43323",
  "name" : null,
  "timestamp" : "2025-03-09T08:46:40.005Z",
  "batchId" : 39,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 15.99520143956813,
  "processedRowsPerSecond" : 18.75512835540968,
  "durationMs" : {
    "addBatch" : 8437,
    "commitOffsets" : 44,
    "getBatch" : 0,
    "latestOffset" : 19,
    "queryPlanning" : 5,
    "triggerExecution" : 8531,
    "walCommit" : 23
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 5950
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 6000
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 6000
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 15.99520143956813,
    "processedRowsPerSecond" : 18.75512835540968,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:16:51 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
25/03/09 14:16:51 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1, groupId=spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor] Request joining group due to: consumer pro-actively leaving the group
25/03/09 14:16:51 INFO Metrics: Metrics scheduler closed
25/03/09 14:16:51 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
25/03/09 14:16:51 INFO CassandraConnector: Disconnected from Cassandra cluster.
25/03/09 14:16:51 INFO Metrics: Metrics reporters closed
25/03/09 14:16:51 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
25/03/09 14:16:51 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-cdb2d6e3-8d97-4282-aada-744751b05216-464444625-executor-1 unregistered
25/03/09 14:16:51 INFO SparkContext: Invoking stop() from shutdown hook
25/03/09 14:16:51 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/03/09 14:16:51 INFO SparkUI: Stopped Spark web UI at http://192.168.0.201:4040
25/03/09 14:16:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/03/09 14:16:51 INFO MemoryStore: MemoryStore cleared
25/03/09 14:16:51 INFO BlockManager: BlockManager stopped
25/03/09 14:16:51 INFO BlockManagerMaster: BlockManagerMaster stopped
25/03/09 14:16:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/03/09 14:16:51 INFO SparkContext: Successfully stopped SparkContext
25/03/09 14:16:51 INFO ShutdownHookManager: Shutdown hook called
25/03/09 14:16:51 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-d49be29b-9594-44b4-bf93-03fcf3228e49
25/03/09 14:16:51 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-d8d8c3b9-6eb4-472c-97a3-16b89131133a
25/03/09 14:16:51 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-d8d8c3b9-6eb4-472c-97a3-16b89131133a/pyspark-37f7c0e3-921c-471c-82d2-8769ed1040e9
/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
25/03/09 14:27:48 WARN Utils: Your hostname, Rachits-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.201 instead (on interface en0)
25/03/09 14:27:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
:: loading settings :: url = jar:file:/opt/homebrew/Cellar/apache-spark/3.5.1/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /Users/rachitmishra/.ivy2/cache
The jars for the packages stored in: /Users/rachitmishra/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-10e57cd1-c4f2-4f82-b697-316126c16f5f;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
	found org.apache.kafka#kafka-clients;3.4.1 in local-m2-cache
	found org.lz4#lz4-java;1.8.0 in local-m2-cache
	found org.xerial.snappy#snappy-java;1.1.10.3 in central
	found org.slf4j#slf4j-api;2.0.7 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.apache.commons#commons-pool2;2.11.1 in central
	found com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central
	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central
	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
	found com.datastax.oss#native-protocol;1.5.0 in central
	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
	found com.typesafe#config;1.4.1 in central
	found io.dropwizard.metrics#metrics-core;4.1.18 in central
	found org.hdrhistogram#HdrHistogram;2.1.12 in central
	found org.reactivestreams#reactive-streams;1.0.3 in central
	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
	found com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache
	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
	found org.apache.commons#commons-lang3;3.10 in central
	found com.thoughtworks.paranamer#paranamer;2.8 in central
	found org.scala-lang#scala-reflect;2.12.11 in central
:: resolution report :: resolve 558ms :: artifacts dl 20ms
	:: modules in use:
	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
	com.datastax.oss#native-protocol;1.5.0 from central in [default]
	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]
	com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]
	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
	com.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]
	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
	com.typesafe#config;1.4.1 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
	org.apache.commons#commons-lang3;3.10 from central in [default]
	org.apache.commons#commons-pool2;2.11.1 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
	org.apache.kafka#kafka-clients;3.4.1 from local-m2-cache in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
	org.lz4#lz4-java;1.8.0 from local-m2-cache in [default]
	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
	org.scala-lang#scala-reflect;2.12.11 from central in [default]
	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
	org.slf4j#slf4j-api;2.0.7 from central in [default]
	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
	:: evicted modules:
	com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   30  |   0   |   0   |   2   ||   28  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-10e57cd1-c4f2-4f82-b697-316126c16f5f
	confs: [default]
	0 artifacts copied, 28 already retrieved (0kB/12ms)
25/03/09 14:27:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/09 14:27:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/03/09 14:27:50 INFO SharedState: Warehouse path is 'file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark-warehouse'.
2025-03-09 14:27:51,395 - INFO - Setting up ScyllaDB...
2025-03-09 14:27:51,396 - WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['localhost'], lbp = None)
2025-03-09 14:27:51,505 - WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-03-09 14:27:51,506 - WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-03-09 14:27:51,508 - WARNING - An authentication challenge was not sent, this is suspicious because the driver expects authentication (configured authenticator = PlainTextAuthenticator)
2025-03-09 14:27:51,514 - INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
2025-03-09 14:27:51,514 - INFO - Cassandra host ::1:9042 removed
2025-03-09 14:27:51,530 - WARNING - An authentication challenge was not sent, this is suspicious because the driver expects authentication (configured authenticator = PlainTextAuthenticator)
2025-03-09 14:27:51,531 - INFO - Creating keyspace...
2025-03-09 14:27:51,534 - INFO - Table 'articles' already exists, checking for required columns...
2025-03-09 14:27:51,536 - INFO - Found columns: {'seendate', 'sourcecountry', 'processed_at', 'sentiment', 'language', 'title', 'socialimage', 'url', 'domain'}
2025-03-09 14:27:51,536 - INFO - ScyllaDB setup completed successfully
2025-03-09 14:27:51,536 - INFO - Created checkpoint directory at /Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint
2025-03-09 14:27:51,536 - INFO - Starting Spark Streaming...
2025-03-09 14:27:52,161 - INFO - Callback Server Starting
2025-03-09 14:27:52,161 - INFO - Socket listening on ('127.0.0.1', 56077)
25/03/09 14:27:52 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/03/09 14:27:52 INFO ResolveWriteToStream: Checkpoint root /Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint resolved to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint.
25/03/09 14:27:52 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
25/03/09 14:27:52 INFO MicroBatchExecution: Starting [id = f5703bd5-3704-48be-97ba-9d131710e782, runId = 4f672f76-98a5-465b-b121-ee9c39b6017c]. Use file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint to store the query checkpoint.
2025-03-09 14:27:52,296 - INFO - Spark Streaming started successfully
25/03/09 14:27:52 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@aed4b7e] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@5b57d509]
25/03/09 14:27:52 INFO OffsetSeqLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39
25/03/09 14:27:52 INFO OffsetSeqLog: Getting latest batch 39
25/03/09 14:27:52 INFO OffsetSeqLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39
25/03/09 14:27:52 INFO OffsetSeqLog: Getting latest batch 39
25/03/09 14:27:52 INFO CommitLog: BatchIds found from listing: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39
25/03/09 14:27:52 INFO CommitLog: Getting latest batch 39
25/03/09 14:27:52 INFO MicroBatchExecution: Resuming at batch 40 with committed offsets {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":6000}}} and available offsets {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":6000}}}
25/03/09 14:27:52 INFO MicroBatchExecution: Stream started from {KafkaV2[Subscribe[geopolitics_events]]: {"geopolitics_events":{"0":6000}}}
25/03/09 14:27:52 INFO AdminClientConfig: AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

25/03/09 14:27:52 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, heartbeat.interval.ms, consumer.polltimeoutms, session.timeout.ms, auto.offset.reset]' were supplied but are not used yet.
25/03/09 14:27:52 INFO AppInfoParser: Kafka version: 3.4.1
25/03/09 14:27:52 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
25/03/09 14:27:52 INFO AppInfoParser: Kafka startTimeMs: 1741510672445
25/03/09 14:27:52 WARN KafkaOffsetReaderAdmin: Found incorrect offsets in some partitions (partition, previous offset, fetched offset): ArrayBuffer((geopolitics_events-0,6000,50))
25/03/09 14:27:52 WARN KafkaOffsetReaderAdmin: Retrying to fetch latest offsets because of incorrect offsets
25/03/09 14:27:53 WARN KafkaOffsetReaderAdmin: Found incorrect offsets in some partitions (partition, previous offset, fetched offset): ArrayBuffer((geopolitics_events-0,6000,50))
25/03/09 14:27:53 WARN KafkaOffsetReaderAdmin: Retrying to fetch latest offsets because of incorrect offsets
25/03/09 14:27:54 WARN KafkaOffsetReaderAdmin: Found incorrect offsets in some partitions (partition, previous offset, fetched offset): ArrayBuffer((geopolitics_events-0,6000,50))
25/03/09 14:27:54 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/40 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.40.ebffcb9d-346b-439a-b2d1-e8bf1081cfe5.tmp
25/03/09 14:27:54 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.40.ebffcb9d-346b-439a-b2d1-e8bf1081cfe5.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/40
25/03/09 14:27:54 INFO MicroBatchExecution: Committed offsets for batch 40. Metadata OffsetSeqMetadata(0,1741510674778,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:27:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:27:55 WARN KafkaMicroBatchStream: Partition geopolitics_events-0's offset was changed from 6000 to 50, some data may have been missed. 
Some data may have been lost because they are not available in Kafka any more; either the
 data was aged out by Kafka or the topic may have been deleted before all the data in the
 topic was processed. If you want your streaming query to fail on such cases, set the source
 option "failOnDataLoss" to "true".
    
25/03/09 14:27:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:27:55 WARN KafkaMicroBatchStream: Partition geopolitics_events-0's offset was changed from 6000 to 50, some data may have been missed. 
Some data may have been lost because they are not available in Kafka any more; either the
 data was aged out by Kafka or the topic may have been deleted before all the data in the
 topic was processed. If you want your streaming query to fail on such cases, set the source
 option "failOnDataLoss" to "true".
    
25/03/09 14:27:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:27:55 WARN KafkaMicroBatchStream: Partition geopolitics_events-0's offset was changed from 6000 to 50, some data may have been missed. 
Some data may have been lost because they are not available in Kafka any more; either the
 data was aged out by Kafka or the topic may have been deleted before all the data in the
 topic was processed. If you want your streaming query to fail on such cases, set the source
 option "failOnDataLoss" to "true".
    
25/03/09 14:27:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:27:55 WARN KafkaMicroBatchStream: Partition geopolitics_events-0's offset was changed from 6000 to 50, some data may have been missed. 
Some data may have been lost because they are not available in Kafka any more; either the
 data was aged out by Kafka or the topic may have been deleted before all the data in the
 topic was processed. If you want your streaming query to fail on such cases, set the source
 option "failOnDataLoss" to "true".
    
25/03/09 14:27:55 INFO CodeGenerator: Code generated in 175.557625 ms
2025-03-09 14:27:55,534 - INFO - Python Server ready to receive messages
2025-03-09 14:27:55,534 - INFO - Received command c on object id p0
25/03/09 14:27:55 INFO CodeGenerator: Code generated in 5.504459 ms
2025-03-09 14:27:55,570 - INFO - Batch 40 is empty, skipping processing
25/03/09 14:27:55 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/40 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.40.e8541625-00b9-4c39-ad49-3664a90ba54e.tmp
25/03/09 14:27:55 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.40.e8541625-00b9-4c39-ad49-3664a90ba54e.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/40
25/03/09 14:27:55 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "4f672f76-98a5-465b-b121-ee9c39b6017c",
  "name" : null,
  "timestamp" : "2025-03-09T08:57:52.318Z",
  "batchId" : 40,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "addBatch" : 514,
    "commitOffsets" : 32,
    "getBatch" : 2,
    "latestOffset" : 2406,
    "queryPlanning" : 241,
    "triggerExecution" : 3289,
    "walCommit" : 34
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 6000
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 50
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 50
      }
    },
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:28:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:28:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:28:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:28:50 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/41 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.41.9d64c97b-64f3-4cdc-abae-20345e262559.tmp
25/03/09 14:28:50 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.41.9d64c97b-64f3-4cdc-abae-20345e262559.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/41
25/03/09 14:28:50 INFO MicroBatchExecution: Committed offsets for batch 41. Metadata OffsetSeqMetadata(0,1741510730036,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:28:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:28:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:28:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:28:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:28:50,106 - INFO - Received command c on object id p0
25/03/09 14:28:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:50 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:50 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:50 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:28:50 INFO DAGScheduler: Missing parents: List()
25/03/09 14:28:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 42.2 KiB, free 2.2 GiB)
25/03/09 14:28:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2.2 GiB)
25/03/09 14:28:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.201:56071 (size: 15.8 KiB, free: 2.2 GiB)
25/03/09 14:28:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/03/09 14:28:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:28:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/03/09 14:28:50 INFO CodeGenerator: Code generated in 18.527917 ms
25/03/09 14:28:50 INFO CodeGenerator: Code generated in 6.679792 ms
25/03/09 14:28:50 INFO CodeGenerator: Code generated in 15.057167 ms
25/03/09 14:28:50 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=0 partitionId=0
25/03/09 14:28:50 INFO CodeGenerator: Code generated in 9.402791 ms
25/03/09 14:28:50 INFO CodeGenerator: Code generated in 11.913542 ms
25/03/09 14:28:50 INFO ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor
	group.instance.id = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Stage 0:>                                                          (0 + 1) / 1]25/03/09 14:28:50 WARN ConsumerConfig: These configurations '[consumer.polltimeoutms]' were supplied but are not used yet.
25/03/09 14:28:50 INFO AppInfoParser: Kafka version: 3.4.1
25/03/09 14:28:50 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
25/03/09 14:28:50 INFO AppInfoParser: Kafka startTimeMs: 1741510730665
25/03/09 14:28:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Assigned to partition(s): geopolitics_events-0
25/03/09 14:28:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:28:50 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting the last seen epoch of partition geopolitics_events-0 to 0 since the associated topicId changed from null to OSjhBAUGQcSLGP3Enx1-Sw
25/03/09 14:28:50 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Cluster ID: OSUIF7FnTmq8AVu_5YHRzw
25/03/09 14:28:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:28:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:28:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:51 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 619554041 nanos, during time span of 722490458 nanos.
25/03/09 14:28:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1914 bytes result sent to driver
25/03/09 14:28:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 946 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/03/09 14:28:51 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 1.268 s
25/03/09 14:28:51 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:28:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/03/09 14:28:51 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 1.290517 s
                                                                                25/03/09 14:28:51 INFO CodeGenerator: Code generated in 10.846542 ms
25/03/09 14:28:51 INFO CodeGenerator: Code generated in 6.800958 ms
25/03/09 14:28:51 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:51 INFO DAGScheduler: Registering RDD 15 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/03/09 14:28:51 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:51 INFO DAGScheduler: Final stage: ResultStage 2 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/03/09 14:28:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
25/03/09 14:28:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 45.1 KiB, free 2.2 GiB)
25/03/09 14:28:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2.2 GiB)
25/03/09 14:28:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2.2 GiB)
25/03/09 14:28:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/03/09 14:28:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:28:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/03/09 14:28:51 INFO CodeGenerator: Code generated in 4.988333 ms
25/03/09 14:28:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=1 partitionId=0
25/03/09 14:28:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:28:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 1:>                                                          (0 + 1) / 1]25/03/09 14:28:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:28:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:52 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 544194542 nanos, during time span of 563544208 nanos.
25/03/09 14:28:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2301 bytes result sent to driver
25/03/09 14:28:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 607 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/03/09 14:28:52 INFO DAGScheduler: ShuffleMapStage 1 (start at NativeMethodAccessorImpl.java:0) finished in 0.616 s
25/03/09 14:28:52 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:28:52 INFO DAGScheduler: running: Set()
25/03/09 14:28:52 INFO DAGScheduler: waiting: Set(ResultStage 2)
25/03/09 14:28:52 INFO DAGScheduler: failed: Set()
25/03/09 14:28:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/03/09 14:28:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:28:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/03/09 14:28:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:28:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
25/03/09 14:28:52 INFO CodeGenerator: Code generated in 6.196583 ms
25/03/09 14:28:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3995 bytes result sent to driver
25/03/09 14:28:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/03/09 14:28:52 INFO DAGScheduler: ResultStage 2 (start at NativeMethodAccessorImpl.java:0) finished in 0.041 s
25/03/09 14:28:52 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:28:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/03/09 14:28:52 INFO DAGScheduler: Job 1 finished: start at NativeMethodAccessorImpl.java:0, took 0.671703 s
                                                                                2025-03-09 14:28:52,217 - INFO - Processing batch 41 with 50 records
2025-03-09 14:28:52,217 - INFO - Applying sentiment analysis...
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 264.0 B, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.0.201:56071 in memory (size: 15.8 KiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece1 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece2 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece3 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece4 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece4 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece5 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece5 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece6 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece6 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece7 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece7 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece8 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece8 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece9 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece9 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece10 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece10 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece11 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece11 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece12 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece12 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece13 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece13 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece14 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece14 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece15 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece15 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece16 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece16 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece17 stored as bytes in memory (estimated size 4.0 MiB, free 2.2 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece17 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.2 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece18 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece18 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece19 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece19 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece20 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece20 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece21 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece21 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece22 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece22 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece23 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece23 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece24 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece24 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece25 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece25 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece26 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece26 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece27 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece27 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece28 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece28 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece29 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece29 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece30 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece30 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece31 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece31 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece32 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece32 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece33 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece33 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece34 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece34 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece35 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece35 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece36 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece36 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece37 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece37 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece38 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece38 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece39 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece39 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece40 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece40 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece41 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece41 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece42 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece42 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece43 stored as bytes in memory (estimated size 4.0 MiB, free 2.1 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece43 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.1 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece44 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece44 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece45 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece45 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece46 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece46 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece47 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece47 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece48 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece48 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece49 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece49 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece50 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece50 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece51 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece51 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece52 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece52 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece53 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece53 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece54 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece54 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece55 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece55 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece56 stored as bytes in memory (estimated size 4.0 MiB, free 2.0 GiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece56 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2.0 GiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece57 stored as bytes in memory (estimated size 4.0 MiB, free 2045.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece57 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2045.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece58 stored as bytes in memory (estimated size 4.0 MiB, free 2041.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece58 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2041.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece59 stored as bytes in memory (estimated size 4.0 MiB, free 2037.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece59 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2037.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece60 stored as bytes in memory (estimated size 4.0 MiB, free 2033.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece60 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2033.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece61 stored as bytes in memory (estimated size 4.0 MiB, free 2029.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece61 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2029.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece62 stored as bytes in memory (estimated size 4.0 MiB, free 2025.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece62 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2025.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece63 stored as bytes in memory (estimated size 4.0 MiB, free 2021.6 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece63 in memory on 192.168.0.201:56071 (size: 4.0 MiB, free: 2021.6 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_3_piece64 stored as bytes in memory (estimated size 1189.1 KiB, free 2020.4 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_3_piece64 in memory on 192.168.0.201:56071 (size: 1189.1 KiB, free: 2020.4 MiB)
25/03/09 14:28:52 INFO SparkContext: Created broadcast 3 from start at NativeMethodAccessorImpl.java:0
2025-03-09 14:28:52,749 - INFO - DataFrame schema:
2025-03-09 14:28:52,751 - INFO - Sample of processed data:
25/03/09 14:28:52 INFO CodeGenerator: Code generated in 11.028916 ms
25/03/09 14:28:52 INFO CodeGenerator: Code generated in 6.663583 ms
25/03/09 14:28:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:52 INFO DAGScheduler: Got job 2 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:52 INFO DAGScheduler: Final stage: ResultStage 3 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:52 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:28:52 INFO DAGScheduler: Missing parents: List()
25/03/09 14:28:52 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 55.8 KiB, free 2020.4 MiB)
25/03/09 14:28:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.4 MiB)
25/03/09 14:28:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:28:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/03/09 14:28:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:28:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/03/09 14:28:52 INFO CodeGenerator: Code generated in 14.404875 ms
25/03/09 14:28:52 INFO CodeGenerator: Code generated in 3.6245 ms
25/03/09 14:28:53 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=3 partitionId=0
25/03/09 14:28:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:28:53 INFO CodeGenerator: Code generated in 7.873125 ms
25/03/09 14:28:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:28:53 INFO CodeGenerator: Code generated in 7.466625 ms
[Stage 3:>                                                          (0 + 1) / 1]25/03/09 14:28:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:28:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:55 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 531647916 nanos, during time span of 2112953667 nanos.
25/03/09 14:28:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 3467 bytes result sent to driver
25/03/09 14:28:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 2532 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/03/09 14:28:55 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 56072
25/03/09 14:28:55 INFO DAGScheduler: ResultStage 3 (start at NativeMethodAccessorImpl.java:0) finished in 2.548 s
25/03/09 14:28:55 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:28:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/03/09 14:28:55 INFO DAGScheduler: Job 2 finished: start at NativeMethodAccessorImpl.java:0, took 2.561824 s
                                                                                25/03/09 14:28:55 INFO CodeGenerator: Code generated in 6.970041 ms
2025-03-09 14:28:55,995 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:28:55,996 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:28:56 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:56 INFO DAGScheduler: Registering RDD 25 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/03/09 14:28:56 INFO DAGScheduler: Got job 3 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:56 INFO DAGScheduler: Final stage: ResultStage 5 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/03/09 14:28:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
25/03/09 14:28:56 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[25] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:28:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[25] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:56 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/03/09 14:28:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:28:56 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
25/03/09 14:28:56 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=4 partitionId=0
25/03/09 14:28:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:28:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 4:>                                                          (0 + 1) / 1]25/03/09 14:28:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:28:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:56 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 572017750 nanos, during time span of 590448834 nanos.
25/03/09 14:28:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2387 bytes result sent to driver
25/03/09 14:28:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 612 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/03/09 14:28:56 INFO DAGScheduler: ShuffleMapStage 4 (start at NativeMethodAccessorImpl.java:0) finished in 0.624 s
25/03/09 14:28:56 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:28:56 INFO DAGScheduler: running: Set()
25/03/09 14:28:56 INFO DAGScheduler: waiting: Set(ResultStage 5)
25/03/09 14:28:56 INFO DAGScheduler: failed: Set()
25/03/09 14:28:56 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:28:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:56 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/03/09 14:28:56 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:28:56 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
25/03/09 14:28:56 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:28:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:28:56 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 3995 bytes result sent to driver
25/03/09 14:28:56 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:56 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/03/09 14:28:56 INFO DAGScheduler: ResultStage 5 (start at NativeMethodAccessorImpl.java:0) finished in 0.010 s
25/03/09 14:28:56 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:28:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/03/09 14:28:56 INFO DAGScheduler: Job 3 finished: start at NativeMethodAccessorImpl.java:0, took 0.637453 s
                                                                                2025-03-09 14:28:56,660 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:28:56,660 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:28:56 INFO CodeGenerator: Code generated in 6.132458 ms
25/03/09 14:28:56 INFO CodeGenerator: Code generated in 4.91675 ms
25/03/09 14:28:56 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:56 INFO DAGScheduler: Got job 4 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:56 INFO DAGScheduler: Final stage: ResultStage 6 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:56 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:28:56 INFO DAGScheduler: Missing parents: List()
25/03/09 14:28:56 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[33] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:28:56 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:28:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[33] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:56 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/03/09 14:28:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:28:56 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
25/03/09 14:28:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:28:56 INFO CodeGenerator: Code generated in 4.593709 ms
25/03/09 14:28:56 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=6 partitionId=0
25/03/09 14:28:56 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:28:56 INFO CodeGenerator: Code generated in 14.364458 ms
25/03/09 14:28:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:28:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:28:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:28:57 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:57 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:57 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:57 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:28:57 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 6:>                                                          (0 + 1) / 1]25/03/09 14:28:58 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 542604583 nanos, during time span of 2193420917 nanos.
25/03/09 14:28:58 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3994 bytes result sent to driver
25/03/09 14:28:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 2225 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:28:58 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/03/09 14:28:58 INFO DAGScheduler: ResultStage 6 (start at NativeMethodAccessorImpl.java:0) finished in 2.234 s
25/03/09 14:28:58 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/03/09 14:28:58 INFO DAGScheduler: Job 4 finished: start at NativeMethodAccessorImpl.java:0, took 2.236520 s
                                                                                25/03/09 14:28:59 INFO ContactPoints: Contact point localhost:9042 resolves to multiple addresses, will use them all ([localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1])
25/03/09 14:28:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:28:59 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
25/03/09 14:28:59 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:41)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at com.datastax.oss.driver.internal.core.util.Reflection.resolveClass(Reflection.java:329)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:235)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:110)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:377)
	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:773)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
	... 26 more
25/03/09 14:28:59 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:28:59 INFO CassandraConnector: Connected to Cassandra cluster.
25/03/09 14:28:59 INFO CodeGenerator: Code generated in 9.603958 ms
25/03/09 14:28:59 INFO CodeGenerator: Code generated in 15.590625 ms
25/03/09 14:28:59 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@2673d0e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@5fd8feca). The input RDD has 1 partitions.
25/03/09 14:28:59 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:28:59 INFO DAGScheduler: Got job 5 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:28:59 INFO DAGScheduler: Final stage: ResultStage 7 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:28:59 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:28:59 INFO DAGScheduler: Missing parents: List()
25/03/09 14:28:59 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:28:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 60.9 KiB, free 2020.4 MiB)
25/03/09 14:28:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.4 MiB)
25/03/09 14:28:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.201:56071 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:28:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/03/09 14:28:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:28:59 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/03/09 14:28:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:28:59 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
25/03/09 14:29:00 INFO CodeGenerator: Code generated in 6.603917 ms
25/03/09 14:29:00 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=50 untilOffset=100, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=41 taskId=7 partitionId=0
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 50 for partition geopolitics_events-0
25/03/09 14:29:00 INFO CodeGenerator: Code generated in 5.099375 ms
25/03/09 14:29:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 7:>                                                          (0 + 1) / 1]25/03/09 14:29:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=100, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:00 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:03 INFO PythonUDFRunner: Times: total = 3249, boot = 3, init = 1828, finish = 1418
25/03/09 14:29:03 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 7, attempt 0, stage 7.0)
25/03/09 14:29:03 INFO DataWritingSparkTask: Committed partition 0 (task 7, attempt 0, stage 7.0)
25/03/09 14:29:03 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 529250208 nanos, during time span of 3319368375 nanos.
25/03/09 14:29:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2691 bytes result sent to driver
25/03/09 14:29:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 3390 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/03/09 14:29:03 INFO DAGScheduler: ResultStage 7 (start at NativeMethodAccessorImpl.java:0) finished in 3.401 s
25/03/09 14:29:03 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/03/09 14:29:03 INFO DAGScheduler: Job 5 finished: start at NativeMethodAccessorImpl.java:0, took 3.405475 s
                                                                                25/03/09 14:29:03 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@2673d0e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@5fd8feca) is committing.
25/03/09 14:29:03 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@2673d0e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@5fd8feca) committed.
2025-03-09 14:29:03,375 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:29:03,375 - INFO - Successfully processed batch 41
25/03/09 14:29:03 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/41 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.41.6a03305c-a998-4a4a-acc9-2f0edd4d6814.tmp
25/03/09 14:29:03 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.41.6a03305c-a998-4a4a-acc9-2f0edd4d6814.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/41
25/03/09 14:29:03 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "4f672f76-98a5-465b-b121-ee9c39b6017c",
  "name" : null,
  "timestamp" : "2025-03-09T08:58:50.001Z",
  "batchId" : 41,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.00640256102441,
  "processedRowsPerSecond" : 11.929615269907545,
  "durationMs" : {
    "addBatch" : 13288,
    "commitOffsets" : 38,
    "getBatch" : 0,
    "latestOffset" : 34,
    "queryPlanning" : 11,
    "triggerExecution" : 13412,
    "walCommit" : 38
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 50
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 100
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 100
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.00640256102441,
    "processedRowsPerSecond" : 11.929615269907545,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:29:03 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13413 milliseconds
25/03/09 14:29:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:29:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:29:50 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/42 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.42.ba53d7c5-7559-410d-8097-1223fa591e80.tmp
25/03/09 14:29:50 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.42.ba53d7c5-7559-410d-8097-1223fa591e80.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/42
25/03/09 14:29:50 INFO MicroBatchExecution: Committed offsets for batch 42. Metadata OffsetSeqMetadata(0,1741510790029,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:29:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:29:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:29:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:29:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:29:50,078 - INFO - Received command c on object id p0
25/03/09 14:29:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:50 INFO DAGScheduler: Got job 6 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:50 INFO DAGScheduler: Final stage: ResultStage 8 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:50 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:29:50 INFO DAGScheduler: Missing parents: List()
25/03/09 14:29:50 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[44] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:50 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:29:50 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:29:50 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.0.201:56071 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:29:50 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[44] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:50 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/03/09 14:29:50 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.0.201:56071 in memory (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:50 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:29:50 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/03/09 14:29:50 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=8 partitionId=0
25/03/09 14:29:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 8:>                                                          (0 + 1) / 1]25/03/09 14:29:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:50 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 638187000 nanos, during time span of 678588417 nanos.
25/03/09 14:29:50 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1914 bytes result sent to driver
25/03/09 14:29:50 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 691 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:50 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/03/09 14:29:50 INFO DAGScheduler: ResultStage 8 (start at NativeMethodAccessorImpl.java:0) finished in 0.702 s
25/03/09 14:29:50 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/03/09 14:29:50 INFO DAGScheduler: Job 6 finished: start at NativeMethodAccessorImpl.java:0, took 0.706033 s
                                                                                25/03/09 14:29:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:50 INFO DAGScheduler: Registering RDD 46 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/03/09 14:29:50 INFO DAGScheduler: Got job 7 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:50 INFO DAGScheduler: Final stage: ResultStage 10 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/03/09 14:29:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
25/03/09 14:29:50 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[46] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:50 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:29:50 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:29:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:50 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[46] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/03/09 14:29:50 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:29:50 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/03/09 14:29:50 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=9 partitionId=0
25/03/09 14:29:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:29:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:51 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 531661250 nanos, during time span of 537784292 nanos.
25/03/09 14:29:51 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2387 bytes result sent to driver
25/03/09 14:29:51 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.0.201:56071 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:29:51 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 558 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:51 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/03/09 14:29:51 INFO DAGScheduler: ShuffleMapStage 9 (start at NativeMethodAccessorImpl.java:0) finished in 0.570 s
25/03/09 14:29:51 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:29:51 INFO DAGScheduler: running: Set()
25/03/09 14:29:51 INFO DAGScheduler: waiting: Set(ResultStage 10)
25/03/09 14:29:51 INFO DAGScheduler: failed: Set()
25/03/09 14:29:51 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[49] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:51 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:29:51 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 2020.4 MiB)
25/03/09 14:29:51 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.0.201:56071 (size: 6.0 KiB, free: 2020.4 MiB)
25/03/09 14:29:51 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[49] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:51 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/03/09 14:29:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:29:51 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
25/03/09 14:29:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:29:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:29:51 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 3995 bytes result sent to driver
25/03/09 14:29:51 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:51 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/03/09 14:29:51 INFO DAGScheduler: ResultStage 10 (start at NativeMethodAccessorImpl.java:0) finished in 0.008 s
25/03/09 14:29:51 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/03/09 14:29:51 INFO DAGScheduler: Job 7 finished: start at NativeMethodAccessorImpl.java:0, took 0.584335 s
2025-03-09 14:29:51,417 - INFO - Processing batch 42 with 50 records
2025-03-09 14:29:51,417 - INFO - Applying sentiment analysis...
2025-03-09 14:29:51,471 - INFO - DataFrame schema:
2025-03-09 14:29:51,490 - INFO - Sample of processed data:
25/03/09 14:29:51 INFO CodeGenerator: Code generated in 4.672083 ms
25/03/09 14:29:51 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:51 INFO DAGScheduler: Got job 8 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:51 INFO DAGScheduler: Final stage: ResultStage 11 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:51 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:29:51 INFO DAGScheduler: Missing parents: List()
25/03/09 14:29:51 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[54] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:51 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:29:51 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:29:51 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:29:51 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:51 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[54] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:51 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/03/09 14:29:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:29:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
25/03/09 14:29:51 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.0.201:56071 in memory (size: 6.0 KiB, free: 2020.4 MiB)
25/03/09 14:29:51 INFO CodeGenerator: Code generated in 6.784792 ms
25/03/09 14:29:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=11 partitionId=0
25/03/09 14:29:51 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 11:>                                                         (0 + 1) / 1]25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:52 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:52 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:52 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 540170791 nanos, during time span of 682800708 nanos.
25/03/09 14:29:52 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 3467 bytes result sent to driver
25/03/09 14:29:52 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 723 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:52 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/03/09 14:29:52 INFO DAGScheduler: ResultStage 11 (start at NativeMethodAccessorImpl.java:0) finished in 0.734 s
25/03/09 14:29:52 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/03/09 14:29:52 INFO DAGScheduler: Job 8 finished: start at NativeMethodAccessorImpl.java:0, took 0.737948 s
                                                                                root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:28:52.766419|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:28:52.766419|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:28:56.679888|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:28:56.679888|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:28:56.679888| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:28:56.679888| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:28:56.679888|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:29:52,332 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:29:52,333 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:29:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:52 INFO DAGScheduler: Registering RDD 56 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/03/09 14:29:52 INFO DAGScheduler: Got job 9 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:52 INFO DAGScheduler: Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/03/09 14:29:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
25/03/09 14:29:52 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[56] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:29:52 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:52 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:29:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[56] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/03/09 14:29:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:29:52 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
25/03/09 14:29:52 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=12 partitionId=0
25/03/09 14:29:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 12:>                                                         (0 + 1) / 1]25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:52 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 535153958 nanos, during time span of 539693542 nanos.
25/03/09 14:29:52 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2387 bytes result sent to driver
25/03/09 14:29:52 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 554 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:52 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/03/09 14:29:52 INFO DAGScheduler: ShuffleMapStage 12 (start at NativeMethodAccessorImpl.java:0) finished in 0.568 s
25/03/09 14:29:52 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:29:52 INFO DAGScheduler: running: Set()
25/03/09 14:29:52 INFO DAGScheduler: waiting: Set(ResultStage 13)
25/03/09 14:29:52 INFO DAGScheduler: failed: Set()
25/03/09 14:29:52 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[59] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:29:52 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:29:52 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[59] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:52 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/03/09 14:29:52 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:29:52 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
25/03/09 14:29:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:29:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:29:52 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 3995 bytes result sent to driver
25/03/09 14:29:52 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 4 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:52 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/03/09 14:29:52 INFO DAGScheduler: ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:29:52 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/03/09 14:29:52 INFO DAGScheduler: Job 9 finished: start at NativeMethodAccessorImpl.java:0, took 0.576761 s
                                                                                2025-03-09 14:29:52,934 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:29:52,934 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:29:52 INFO CodeGenerator: Code generated in 5.997709 ms
25/03/09 14:29:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:52 INFO DAGScheduler: Got job 10 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:52 INFO DAGScheduler: Final stage: ResultStage 14 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:52 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:29:52 INFO DAGScheduler: Missing parents: List()
25/03/09 14:29:52 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:29:52 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:29:52 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:29:52 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:52 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/03/09 14:29:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:29:52 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:29:52 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
25/03/09 14:29:53 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:53 INFO CodeGenerator: Code generated in 4.241792 ms
25/03/09 14:29:53 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=14 partitionId=0
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:29:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:53 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 14:>                                                         (0 + 1) / 1]25/03/09 14:29:55 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 531949125 nanos, during time span of 2116109750 nanos.
25/03/09 14:29:55 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3994 bytes result sent to driver
25/03/09 14:29:55 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 2136 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:55 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/03/09 14:29:55 INFO DAGScheduler: ResultStage 14 (start at NativeMethodAccessorImpl.java:0) finished in 2.148 s
25/03/09 14:29:55 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/03/09 14:29:55 INFO DAGScheduler: Job 10 finished: start at NativeMethodAccessorImpl.java:0, took 2.154696 s
                                                                                25/03/09 14:29:55 INFO CodeGenerator: Code generated in 3.927083 ms
25/03/09 14:29:55 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@71c134e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2832e925). The input RDD has 1 partitions.
25/03/09 14:29:55 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:29:55 INFO DAGScheduler: Got job 11 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:29:55 INFO DAGScheduler: Final stage: ResultStage 15 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:29:55 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:29:55 INFO DAGScheduler: Missing parents: List()
25/03/09 14:29:55 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[68] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:29:55 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:29:55 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.3 MiB)
25/03/09 14:29:55 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.0.201:56071 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:29:55 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:29:55 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
25/03/09 14:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[68] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:29:55 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/03/09 14:29:55 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:29:55 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
25/03/09 14:29:55 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=100 untilOffset=150, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=42 taskId=15 partitionId=0
25/03/09 14:29:55 INFO CodeGenerator: Code generated in 4.364833 ms
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 100 for partition geopolitics_events-0
25/03/09 14:29:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 15:>                                                         (0 + 1) / 1]25/03/09 14:29:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:29:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=150, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:55 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:29:58 INFO PythonUDFRunner: Times: total = 3031, boot = 3, init = 1712, finish = 1316
25/03/09 14:29:58 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 15, attempt 0, stage 15.0)
25/03/09 14:29:58 INFO DataWritingSparkTask: Committed partition 0 (task 15, attempt 0, stage 15.0)
25/03/09 14:29:58 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 552770125 nanos, during time span of 3073568334 nanos.
25/03/09 14:29:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2691 bytes result sent to driver
25/03/09 14:29:58 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 3106 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:29:58 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/03/09 14:29:58 INFO DAGScheduler: ResultStage 15 (start at NativeMethodAccessorImpl.java:0) finished in 3.117 s
25/03/09 14:29:58 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:29:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/03/09 14:29:58 INFO DAGScheduler: Job 11 finished: start at NativeMethodAccessorImpl.java:0, took 3.119588 s
                                                                                25/03/09 14:29:58 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@71c134e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2832e925) is committing.
25/03/09 14:29:58 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@71c134e1,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@2832e925) committed.
2025-03-09 14:29:58,333 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:29:58,333 - INFO - Successfully processed batch 42
25/03/09 14:29:58 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/42 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.42.37202827-0760-443c-bb29-5623be70ff70.tmp
25/03/09 14:29:58 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.42.37202827-0760-443c-bb29-5623be70ff70.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/42
25/03/09 14:29:58 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "4f672f76-98a5-465b-b121-ee9c39b6017c",
  "name" : null,
  "timestamp" : "2025-03-09T08:59:50.005Z",
  "batchId" : 42,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.001600160016,
  "processedRowsPerSecond" : 19.134178426213825,
  "durationMs" : {
    "addBatch" : 8270,
    "commitOffsets" : 33,
    "getBatch" : 0,
    "latestOffset" : 24,
    "queryPlanning" : 7,
    "triggerExecution" : 8362,
    "walCommit" : 26
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 100
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 150
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 150
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.001600160016,
    "processedRowsPerSecond" : 19.134178426213825,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:30:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:30:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:30:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:30:58 INFO CassandraConnector: Disconnected from Cassandra cluster.
25/03/09 14:31:00 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/43 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.43.571f3e3c-d1e8-49ee-a074-6fd136d08bfa.tmp
25/03/09 14:31:00 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.43.571f3e3c-d1e8-49ee-a074-6fd136d08bfa.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/43
25/03/09 14:31:00 INFO MicroBatchExecution: Committed offsets for batch 43. Metadata OffsetSeqMetadata(0,1741510860029,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:31:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:31:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:31:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:31:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:31:00,084 - INFO - Received command c on object id p0
25/03/09 14:31:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:00 INFO DAGScheduler: Got job 12 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:00 INFO DAGScheduler: Final stage: ResultStage 16 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:00 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:31:00 INFO DAGScheduler: Missing parents: List()
25/03/09 14:31:00 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[75] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:00 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:31:00 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:31:00 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.0.201:56071 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:31:00 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:00 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.0.201:56071 in memory (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:31:00 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
25/03/09 14:31:00 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:31:00 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
25/03/09 14:31:00 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=16 partitionId=0
25/03/09 14:31:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:31:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:00 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 541628250 nanos, during time span of 548618625 nanos.
25/03/09 14:31:00 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1914 bytes result sent to driver
25/03/09 14:31:00 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 557 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:00 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
25/03/09 14:31:00 INFO DAGScheduler: ResultStage 16 (start at NativeMethodAccessorImpl.java:0) finished in 0.565 s
25/03/09 14:31:00 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
25/03/09 14:31:00 INFO DAGScheduler: Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 0.568390 s
25/03/09 14:31:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:00 INFO DAGScheduler: Registering RDD 77 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/03/09 14:31:00 INFO DAGScheduler: Got job 13 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:00 INFO DAGScheduler: Final stage: ResultStage 18 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
25/03/09 14:31:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
25/03/09 14:31:00 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[77] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:00 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:31:00 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:31:00 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:31:00 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[77] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:00 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/03/09 14:31:00 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:31:00 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
25/03/09 14:31:00 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=17 partitionId=0
25/03/09 14:31:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:01 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 522903375 nanos, during time span of 526998875 nanos.
25/03/09 14:31:01 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2387 bytes result sent to driver
25/03/09 14:31:01 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.0.201:56071 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:31:01 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 549 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:01 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/03/09 14:31:01 INFO DAGScheduler: ShuffleMapStage 17 (start at NativeMethodAccessorImpl.java:0) finished in 0.552 s
25/03/09 14:31:01 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:31:01 INFO DAGScheduler: running: Set()
25/03/09 14:31:01 INFO DAGScheduler: waiting: Set(ResultStage 18)
25/03/09 14:31:01 INFO DAGScheduler: failed: Set()
25/03/09 14:31:01 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[80] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:01 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:31:01 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:31:01 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:31:01 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[80] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:01 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
25/03/09 14:31:01 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:31:01 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
25/03/09 14:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:31:01 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 3952 bytes result sent to driver
25/03/09 14:31:01 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:01 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/03/09 14:31:01 INFO DAGScheduler: ResultStage 18 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:31:01 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
25/03/09 14:31:01 INFO DAGScheduler: Job 13 finished: start at NativeMethodAccessorImpl.java:0, took 0.561423 s
2025-03-09 14:31:01,246 - INFO - Processing batch 43 with 50 records
2025-03-09 14:31:01,246 - INFO - Applying sentiment analysis...
2025-03-09 14:31:01,256 - INFO - DataFrame schema:
2025-03-09 14:31:01,257 - INFO - Sample of processed data:
25/03/09 14:31:01 INFO CodeGenerator: Code generated in 4.6295 ms
25/03/09 14:31:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:01 INFO DAGScheduler: Got job 14 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:01 INFO DAGScheduler: Final stage: ResultStage 19 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:01 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:31:01 INFO DAGScheduler: Missing parents: List()
25/03/09 14:31:01 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[85] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:01 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:31:01 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:31:01 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:31:01 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[85] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:01 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/03/09 14:31:01 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:31:01 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
25/03/09 14:31:01 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:31:01 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:31:01 INFO CodeGenerator: Code generated in 4.732292 ms
25/03/09 14:31:01 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=19 partitionId=0
25/03/09 14:31:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 19:>                                                         (0 + 1) / 1]25/03/09 14:31:02 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 528505250 nanos, during time span of 671067333 nanos.
25/03/09 14:31:02 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 3467 bytes result sent to driver
25/03/09 14:31:02 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 714 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:02 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/03/09 14:31:02 INFO DAGScheduler: ResultStage 19 (start at NativeMethodAccessorImpl.java:0) finished in 0.751 s
25/03/09 14:31:02 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/03/09 14:31:02 INFO DAGScheduler: Job 14 finished: start at NativeMethodAccessorImpl.java:0, took 0.753005 s
                                                                                +-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:29:51.520766|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:29:51.520766|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:29:52.941151|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:29:52.941151|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:29:52.941151| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:29:52.941151| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:29:52.941151|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:31:02,064 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:31:02,065 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:31:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:02 INFO DAGScheduler: Registering RDD 87 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 5
25/03/09 14:31:02 INFO DAGScheduler: Got job 15 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:02 INFO DAGScheduler: Final stage: ResultStage 21 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
25/03/09 14:31:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
25/03/09 14:31:02 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[87] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:31:02 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.0.201:56071 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:31:02 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[87] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:02 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
25/03/09 14:31:02 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:31:02 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
25/03/09 14:31:02 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=20 partitionId=0
25/03/09 14:31:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 20:>                                                         (0 + 1) / 1]25/03/09 14:31:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:02 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 535488834 nanos, during time span of 539493584 nanos.
25/03/09 14:31:02 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:31:02 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2387 bytes result sent to driver
25/03/09 14:31:02 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 553 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:02 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
25/03/09 14:31:02 INFO DAGScheduler: ShuffleMapStage 20 (start at NativeMethodAccessorImpl.java:0) finished in 0.558 s
25/03/09 14:31:02 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:31:02 INFO DAGScheduler: running: Set()
25/03/09 14:31:02 INFO DAGScheduler: waiting: Set(ResultStage 21)
25/03/09 14:31:02 INFO DAGScheduler: failed: Set()
25/03/09 14:31:02 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[90] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:31:02 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:31:02 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[90] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:02 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
25/03/09 14:31:02 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:31:02 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
25/03/09 14:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:31:02 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 3952 bytes result sent to driver
25/03/09 14:31:02 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:02 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
25/03/09 14:31:02 INFO DAGScheduler: ResultStage 21 (start at NativeMethodAccessorImpl.java:0) finished in 0.005 s
25/03/09 14:31:02 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
25/03/09 14:31:02 INFO DAGScheduler: Job 15 finished: start at NativeMethodAccessorImpl.java:0, took 0.567137 s
                                                                                2025-03-09 14:31:02,664 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:31:02,664 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:31:02 INFO CodeGenerator: Code generated in 4.264875 ms
25/03/09 14:31:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:02 INFO DAGScheduler: Got job 16 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:02 INFO DAGScheduler: Final stage: ResultStage 22 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:02 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:31:02 INFO DAGScheduler: Missing parents: List()
25/03/09 14:31:02 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[95] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:31:02 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:31:02 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:31:02 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[95] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:02 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
25/03/09 14:31:02 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:31:02 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
25/03/09 14:31:02 INFO CodeGenerator: Code generated in 3.412042 ms
25/03/09 14:31:02 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=22 partitionId=0
25/03/09 14:31:02 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 22:>                                                         (0 + 1) / 1]25/03/09 14:31:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:04 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 541216625 nanos, during time span of 2100367916 nanos.
25/03/09 14:31:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:31:04 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3994 bytes result sent to driver
25/03/09 14:31:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 2116 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
25/03/09 14:31:04 INFO DAGScheduler: ResultStage 22 (start at NativeMethodAccessorImpl.java:0) finished in 2.119 s
25/03/09 14:31:04 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
25/03/09 14:31:04 INFO DAGScheduler: Job 16 finished: start at NativeMethodAccessorImpl.java:0, took 2.122675 s
                                                                                25/03/09 14:31:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.0.201:56071 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:31:04 INFO ContactPoints: Contact point localhost:9042 resolves to multiple addresses, will use them all ([localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1])
25/03/09 14:31:04 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 WARN PlainTextAuthProviderBase: [] localhost/127.0.0.1:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication
25/03/09 14:31:04 INFO CassandraConnector: Connected to Cassandra cluster.
25/03/09 14:31:04 INFO CodeGenerator: Code generated in 4.529667 ms
25/03/09 14:31:04 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@36af49b2,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@aaea87b). The input RDD has 1 partitions.
25/03/09 14:31:04 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:31:04 INFO DAGScheduler: Got job 17 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:31:04 INFO DAGScheduler: Final stage: ResultStage 23 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:31:04 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:31:04 INFO DAGScheduler: Missing parents: List()
25/03/09 14:31:04 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:31:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:31:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.3 MiB)
25/03/09 14:31:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.0.201:56071 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:31:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:31:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
25/03/09 14:31:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:31:04 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
25/03/09 14:31:04 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:31:04 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
25/03/09 14:31:04 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=150 untilOffset=200, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=43 taskId=23 partitionId=0
25/03/09 14:31:04 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:04 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 150 for partition geopolitics_events-0
25/03/09 14:31:04 INFO CodeGenerator: Code generated in 9.646375 ms
25/03/09 14:31:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
[Stage 23:>                                                         (0 + 1) / 1]25/03/09 14:31:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:31:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=200, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:31:07 INFO PythonUDFRunner: Times: total = 2919, boot = 3, init = 1657, finish = 1259
25/03/09 14:31:07 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 23, attempt 0, stage 23.0)
25/03/09 14:31:07 INFO DataWritingSparkTask: Committed partition 0 (task 23, attempt 0, stage 23.0)
25/03/09 14:31:07 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 548895042 nanos, during time span of 2949693792 nanos.
25/03/09 14:31:07 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2691 bytes result sent to driver
25/03/09 14:31:07 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 2974 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:31:07 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
25/03/09 14:31:07 INFO DAGScheduler: ResultStage 23 (start at NativeMethodAccessorImpl.java:0) finished in 2.984 s
25/03/09 14:31:07 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:31:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
25/03/09 14:31:07 INFO DAGScheduler: Job 17 finished: start at NativeMethodAccessorImpl.java:0, took 2.986786 s
                                                                                25/03/09 14:31:07 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@36af49b2,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@aaea87b) is committing.
25/03/09 14:31:07 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@36af49b2,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@aaea87b) committed.
2025-03-09 14:31:07,917 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:31:07,917 - INFO - Successfully processed batch 43
25/03/09 14:31:07 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/43 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.43.da02238d-81cd-40e9-a50a-d796e5dc3ed3.tmp
25/03/09 14:31:07 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.43.da02238d-81cd-40e9-a50a-d796e5dc3ed3.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/43
25/03/09 14:31:07 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "4f672f76-98a5-465b-b121-ee9c39b6017c",
  "name" : null,
  "timestamp" : "2025-03-09T09:01:00.001Z",
  "batchId" : 43,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.00640256102441,
  "processedRowsPerSecond" : 20.128318027424832,
  "durationMs" : {
    "addBatch" : 7846,
    "commitOffsets" : 33,
    "getBatch" : 0,
    "latestOffset" : 28,
    "queryPlanning" : 7,
    "triggerExecution" : 7949,
    "walCommit" : 34
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 150
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 200
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 200
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.00640256102441,
    "processedRowsPerSecond" : 20.128318027424832,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:31:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:31:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:31:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:32:00 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/44 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.44.6c97a962-c10f-4595-a766-117ac90c43cc.tmp
25/03/09 14:32:00 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/.44.6c97a962-c10f-4595-a766-117ac90c43cc.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/offsets/44
25/03/09 14:32:00 INFO MicroBatchExecution: Committed offsets for batch 44. Metadata OffsetSeqMetadata(0,1741510920029,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 4))
25/03/09 14:32:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:32:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:32:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/03/09 14:32:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2025-03-09 14:32:00,071 - INFO - Received command c on object id p0
25/03/09 14:32:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:00 INFO DAGScheduler: Got job 18 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:00 INFO DAGScheduler: Final stage: ResultStage 24 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:00 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:32:00 INFO DAGScheduler: Missing parents: List()
25/03/09 14:32:00 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[106] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:00 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 42.2 KiB, free 2020.3 MiB)
25/03/09 14:32:00 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2020.3 MiB)
25/03/09 14:32:00 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.0.201:56071 (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:32:00 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.0.201:56071 in memory (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:32:00 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[106] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:00 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
25/03/09 14:32:00 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:32:00 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
25/03/09 14:32:00 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=24 partitionId=0
25/03/09 14:32:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:32:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:00 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 1 records through 1 polls (polled  out 50 records), taking 528572042 nanos, during time span of 538257042 nanos.
25/03/09 14:32:00 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1914 bytes result sent to driver
25/03/09 14:32:00 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 545 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:00 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
25/03/09 14:32:00 INFO DAGScheduler: ResultStage 24 (start at NativeMethodAccessorImpl.java:0) finished in 0.552 s
25/03/09 14:32:00 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
25/03/09 14:32:00 INFO DAGScheduler: Job 18 finished: start at NativeMethodAccessorImpl.java:0, took 0.553739 s
25/03/09 14:32:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:00 INFO DAGScheduler: Registering RDD 108 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 6
25/03/09 14:32:00 INFO DAGScheduler: Got job 19 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:00 INFO DAGScheduler: Final stage: ResultStage 26 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
25/03/09 14:32:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
25/03/09 14:32:00 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[108] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:00 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:32:00 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2020.3 MiB)
25/03/09 14:32:00 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.0.201:56071 (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:32:00 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[108] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:00 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
25/03/09 14:32:00 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:32:00 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
25/03/09 14:32:00 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=25 partitionId=0
25/03/09 14:32:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:01 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 546635125 nanos, during time span of 550607000 nanos.
25/03/09 14:32:01 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2387 bytes result sent to driver
25/03/09 14:32:01 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 577 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:01 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
25/03/09 14:32:01 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.0.201:56071 in memory (size: 15.8 KiB, free: 2020.4 MiB)
25/03/09 14:32:01 INFO DAGScheduler: ShuffleMapStage 25 (start at NativeMethodAccessorImpl.java:0) finished in 0.581 s
25/03/09 14:32:01 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:32:01 INFO DAGScheduler: running: Set()
25/03/09 14:32:01 INFO DAGScheduler: waiting: Set(ResultStage 26)
25/03/09 14:32:01 INFO DAGScheduler: failed: Set()
25/03/09 14:32:01 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:01 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:32:01 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:32:01 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:32:01 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:01 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
25/03/09 14:32:01 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:32:01 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
25/03/09 14:32:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:32:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:32:01 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 3995 bytes result sent to driver
25/03/09 14:32:01 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:01 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
25/03/09 14:32:01 INFO DAGScheduler: ResultStage 26 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:32:01 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
25/03/09 14:32:01 INFO DAGScheduler: Job 19 finished: start at NativeMethodAccessorImpl.java:0, took 0.590490 s
2025-03-09 14:32:01,242 - INFO - Processing batch 44 with 50 records
2025-03-09 14:32:01,242 - INFO - Applying sentiment analysis...
2025-03-09 14:32:01,251 - INFO - DataFrame schema:
2025-03-09 14:32:01,251 - INFO - Sample of processed data:
25/03/09 14:32:01 INFO CodeGenerator: Code generated in 7.462708 ms
25/03/09 14:32:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:01 INFO DAGScheduler: Got job 20 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:01 INFO DAGScheduler: Final stage: ResultStage 27 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:01 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:32:01 INFO DAGScheduler: Missing parents: List()
25/03/09 14:32:01 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[116] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:01 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:32:01 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:32:01 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:32:01 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:01 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:32:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[116] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:01 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
25/03/09 14:32:01 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:32:01 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
25/03/09 14:32:01 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.0.201:56071 in memory (size: 17.2 KiB, free: 2020.4 MiB)
25/03/09 14:32:01 INFO CodeGenerator: Code generated in 6.822292 ms
25/03/09 14:32:01 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=27 partitionId=0
25/03/09 14:32:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
[Stage 27:>                                                         (0 + 1) / 1]25/03/09 14:32:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:01 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:02 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 3 records through 1 polls (polled  out 50 records), taking 569913917 nanos, during time span of 711346292 nanos.
25/03/09 14:32:02 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 3467 bytes result sent to driver
25/03/09 14:32:02 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 741 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:02 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
25/03/09 14:32:02 INFO DAGScheduler: ResultStage 27 (start at NativeMethodAccessorImpl.java:0) finished in 0.749 s
25/03/09 14:32:02 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
25/03/09 14:32:02 INFO DAGScheduler: Job 20 finished: start at NativeMethodAccessorImpl.java:0, took 0.751187 s
                                                                                +-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:31:01.272342|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:31:01.272342|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:31:02.670498|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:31:02.670498|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:31:02.670498| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:31:02.670498| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:31:02.670498|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

root
 |-- url: string (nullable = true)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)

2025-03-09 14:32:02,073 - INFO - Final DataFrame schema after column selection:
2025-03-09 14:32:02,073 - INFO - Attempting to write to ScyllaDB (attempt 1/3)...
25/03/09 14:32:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:02 INFO DAGScheduler: Registering RDD 118 (start at NativeMethodAccessorImpl.java:0) as input to shuffle 7
25/03/09 14:32:02 INFO DAGScheduler: Got job 21 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:02 INFO DAGScheduler: Final stage: ResultStage 29 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
25/03/09 14:32:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
25/03/09 14:32:02 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[118] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 45.1 KiB, free 2020.3 MiB)
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 2020.3 MiB)
25/03/09 14:32:02 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.0.201:56071 (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:32:02 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[118] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:02 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
25/03/09 14:32:02 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14354 bytes) 
25/03/09 14:32:02 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
25/03/09 14:32:02 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=28 partitionId=0
25/03/09 14:32:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:32:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:02 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 528014417 nanos, during time span of 531011541 nanos.
25/03/09 14:32:02 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2387 bytes result sent to driver
25/03/09 14:32:02 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 542 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:02 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
25/03/09 14:32:02 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:32:02 INFO DAGScheduler: ShuffleMapStage 28 (start at NativeMethodAccessorImpl.java:0) finished in 0.546 s
25/03/09 14:32:02 INFO DAGScheduler: looking for newly runnable stages
25/03/09 14:32:02 INFO DAGScheduler: running: Set()
25/03/09 14:32:02 INFO DAGScheduler: waiting: Set(ResultStage 29)
25/03/09 14:32:02 INFO DAGScheduler: failed: Set()
25/03/09 14:32:02 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[121] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 2020.4 MiB)
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2020.4 MiB)
25/03/09 14:32:02 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.0.201:56071 (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:32:02 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[121] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:02 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
25/03/09 14:32:02 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (192.168.0.201, executor driver, partition 0, NODE_LOCAL, 13294 bytes) 
25/03/09 14:32:02 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
25/03/09 14:32:02 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/09 14:32:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/09 14:32:02 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 3995 bytes result sent to driver
25/03/09 14:32:02 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 3 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:02 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
25/03/09 14:32:02 INFO DAGScheduler: ResultStage 29 (start at NativeMethodAccessorImpl.java:0) finished in 0.006 s
25/03/09 14:32:02 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
25/03/09 14:32:02 INFO DAGScheduler: Job 21 finished: start at NativeMethodAccessorImpl.java:0, took 0.554467 s
2025-03-09 14:32:02,646 - INFO - Writing 50 records to ScyllaDB
2025-03-09 14:32:02,646 - INFO - Sample of records being written to ScyllaDB:
25/03/09 14:32:02 INFO CodeGenerator: Code generated in 5.269708 ms
25/03/09 14:32:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:02 INFO DAGScheduler: Got job 22 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:02 INFO DAGScheduler: Final stage: ResultStage 30 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:02 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:32:02 INFO DAGScheduler: Missing parents: List()
25/03/09 14:32:02 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[126] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 55.8 KiB, free 2020.3 MiB)
25/03/09 14:32:02 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 2020.3 MiB)
25/03/09 14:32:02 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.0.201:56071 (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:32:02 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[126] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:02 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
25/03/09 14:32:02 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:32:02 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
25/03/09 14:32:02 INFO CodeGenerator: Code generated in 3.492667 ms
25/03/09 14:32:02 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=30 partitionId=0
25/03/09 14:32:02 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:32:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:03 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 30:>                                                         (0 + 1) / 1]25/03/09 14:32:04 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 6 records through 1 polls (polled  out 50 records), taking 529180833 nanos, during time span of 2116526334 nanos.
25/03/09 14:32:04 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.0.201:56071 in memory (size: 5.9 KiB, free: 2020.4 MiB)
25/03/09 14:32:04 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 3994 bytes result sent to driver
25/03/09 14:32:04 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 2134 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:04 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
25/03/09 14:32:04 INFO DAGScheduler: ResultStage 30 (start at NativeMethodAccessorImpl.java:0) finished in 2.138 s
25/03/09 14:32:04 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
25/03/09 14:32:04 INFO DAGScheduler: Job 22 finished: start at NativeMethodAccessorImpl.java:0, took 2.142951 s
                                                                                25/03/09 14:32:04 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.0.201:56071 in memory (size: 17.3 KiB, free: 2020.4 MiB)
25/03/09 14:32:04 INFO CodeGenerator: Code generated in 7.778125 ms
25/03/09 14:32:04 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@a207fa4,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@594ec386). The input RDD has 1 partitions.
25/03/09 14:32:04 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
25/03/09 14:32:04 INFO DAGScheduler: Got job 23 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/09 14:32:04 INFO DAGScheduler: Final stage: ResultStage 31 (start at NativeMethodAccessorImpl.java:0)
25/03/09 14:32:04 INFO DAGScheduler: Parents of final stage: List()
25/03/09 14:32:04 INFO DAGScheduler: Missing parents: List()
25/03/09 14:32:04 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[130] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/09 14:32:04 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 60.9 KiB, free 2020.3 MiB)
25/03/09 14:32:04 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2020.3 MiB)
25/03/09 14:32:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.0.201:56071 (size: 23.2 KiB, free: 2020.4 MiB)
25/03/09 14:32:04 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
25/03/09 14:32:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[130] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/09 14:32:04 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
25/03/09 14:32:04 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 192.168.0.201:56071 in memory (size: 20.7 KiB, free: 2020.4 MiB)
25/03/09 14:32:04 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (192.168.0.201, executor driver, partition 0, PROCESS_LOCAL, 14365 bytes) 
25/03/09 14:32:04 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
25/03/09 14:32:04 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=geopolitics_events-0 fromOffset=200 untilOffset=250, for query queryId=f5703bd5-3704-48be-97ba-9d131710e782 batchId=44 taskId=31 partitionId=0
25/03/09 14:32:04 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:04 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to offset 200 for partition geopolitics_events-0
25/03/09 14:32:04 INFO CodeGenerator: Code generated in 3.718083 ms
25/03/09 14:32:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to earliest offset of partition geopolitics_events-0
25/03/09 14:32:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Seeking to latest offset of partition geopolitics_events-0
25/03/09 14:32:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting offset for partition geopolitics_events-0 to position FetchPosition{offset=250, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}.
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
25/03/09 14:32:05 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[Stage 31:>                                                         (0 + 1) / 1]25/03/09 14:32:08 INFO PythonUDFRunner: Times: total = 3105, boot = 4, init = 1675, finish = 1426
25/03/09 14:32:08 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 31, attempt 0, stage 31.0)
25/03/09 14:32:08 INFO DataWritingSparkTask: Committed partition 0 (task 31, attempt 0, stage 31.0)
25/03/09 14:32:08 INFO KafkaDataConsumer: From Kafka topicPartition=geopolitics_events-0 groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor read 50 records through 1 polls (polled  out 50 records), taking 528924792 nanos, during time span of 3132511750 nanos.
25/03/09 14:32:08 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2691 bytes result sent to driver
25/03/09 14:32:08 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 3152 ms on 192.168.0.201 (executor driver) (1/1)
25/03/09 14:32:08 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
25/03/09 14:32:08 INFO DAGScheduler: ResultStage 31 (start at NativeMethodAccessorImpl.java:0) finished in 3.160 s
25/03/09 14:32:08 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/09 14:32:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
25/03/09 14:32:08 INFO DAGScheduler: Job 23 finished: start at NativeMethodAccessorImpl.java:0, took 3.163108 s
                                                                                25/03/09 14:32:08 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@a207fa4,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@594ec386) is committing.
25/03/09 14:32:08 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@41f98094,com.datastax.spark.connector.cql.CassandraConnector@a207fa4,TableDef(geopolitics,articles,ArrayBuffer(ColumnDef(url,PartitionKeyColumn,VarCharType)),ArrayBuffer(ColumnDef(processed_at,ClusteringColumn(0,ASC),TimestampType)),Stream(ColumnDef(domain,RegularColumn,VarCharType), ColumnDef(language,RegularColumn,VarCharType), ColumnDef(seendate,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(socialimage,RegularColumn,VarCharType), ColumnDef(sourcecountry,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(RowsInBatch(10),100,Partition,LOCAL_ONE,false,true,1,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(url,StringType,true),StructField(processed_at,TimestampType,false),StructField(title,StringType,true),StructField(seendate,StringType,true),StructField(socialimage,StringType,true),StructField(domain,StringType,true),StructField(language,StringType,true),StructField(sourcecountry,StringType,true),StructField(sentiment,StringType,true)),org.apache.spark.SparkConf@594ec386) committed.
2025-03-09 14:32:08,054 - INFO - Successfully wrote batch to ScyllaDB
2025-03-09 14:32:08,055 - INFO - Successfully processed batch 44
25/03/09 14:32:08 INFO CheckpointFileManager: Writing atomically to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/44 using temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.44.5a05f4c8-0cb6-4b63-a21a-fe719239447b.tmp
25/03/09 14:32:08 INFO CheckpointFileManager: Renamed temp file file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/.44.5a05f4c8-0cb6-4b63-a21a-fe719239447b.tmp to file:/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/checkpoint/commits/44
25/03/09 14:32:08 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "f5703bd5-3704-48be-97ba-9d131710e782",
  "runId" : "4f672f76-98a5-465b-b121-ee9c39b6017c",
  "name" : null,
  "timestamp" : "2025-03-09T09:02:00.002Z",
  "batchId" : 44,
  "numInputRows" : 160,
  "inputRowsPerSecond" : 16.00480144043213,
  "processedRowsPerSecond" : 19.767729182110205,
  "durationMs" : {
    "addBatch" : 7994,
    "commitOffsets" : 41,
    "getBatch" : 0,
    "latestOffset" : 27,
    "queryPlanning" : 5,
    "triggerExecution" : 8094,
    "walCommit" : 27
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[geopolitics_events]]",
    "startOffset" : {
      "geopolitics_events" : {
        "0" : 200
      }
    },
    "endOffset" : {
      "geopolitics_events" : {
        "0" : 250
      }
    },
    "latestOffset" : {
      "geopolitics_events" : {
        "0" : 250
      }
    },
    "numInputRows" : 160,
    "inputRowsPerSecond" : 16.00480144043213,
    "processedRowsPerSecond" : 19.767729182110205,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
25/03/09 14:32:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/03/09 14:32:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
2025-03-09 14:32:40,869 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=6>
2025-03-09 14:32:40,869 - INFO - Closing down clientserver connection
2025-03-09 14:32:40,869 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=6>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-03-09 14:32:40,870 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o68.sc
2025-03-09 14:32:40,870 - INFO - Closing down clientserver connection
2025-03-09 14:32:40,870 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o68.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-03-09 14:32:40,871 - INFO - Closing down clientserver connection
2025-03-09 14:32:40,871 - ERROR - Error in streaming query: An error occurred while calling o112.awaitTermination
Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark_streaming/spark_streaming.py", line 267, in main
    query.awaitTermination(10)  # Check every 10 seconds
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/sql/streaming/query.py", line 219, in awaitTermination
    return self._jsq.awaitTermination(int(timeout * 1000))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o112.awaitTermination
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|url                                                                                  |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain           |language |sourcecountry|sentiment|processed_at              |
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn|Chinese  |China        |NEGATIVE |2025-03-09 14:32:01.257165|
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua           |Ukrainian|Ukraine      |POSITIVE |2025-03-09 14:32:01.257165|
+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------+-------------+---------+--------------------------+
only showing top 2 rows

root
 |-- url: string (nullable = true)
 |-- processed_at: timestamp (nullable = false)
 |-- title: string (nullable = true)
 |-- seendate: string (nullable = true)
 |-- socialimage: string (nullable = true)
 |-- domain: string (nullable = true)
 |-- language: string (nullable = true)
 |-- sourcecountry: string (nullable = true)
 |-- sentiment: string (nullable = true)

+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|url                                                                                  |processed_at              |title                                                                                   |seendate        |socialimage                                                                                                                                 |domain             |language |sourcecountry|sentiment|
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
|http://news.china.com.cn/2025-01/29/content_117690124.shtml                          |2025-03-09 14:32:02.651763|                                            |20250129T020000Z|                                                                                                                                            |news.china.com.cn  |Chinese  |China        |NEGATIVE |
|https://www.rbc.ua/rus/news/absolyutna-bilshist-krayin-nato-vvazhayut-1738262441.html|2025-03-09 14:32:02.651763|         ,  |20250130T200000Z|https://www.rbc.ua/static/img/_/s/_stefanishina__foto__vitalii___nosach_rbk_ukrai__na_9292__1__48e1b913edf04ebba8fbc30c3a89bca5_1300x820.jpg|rbc.ua             |Ukrainian|Ukraine      |POSITIVE |
|http://www.xinhuanet.com/20250129/61ec83f4dff642b6a77a1264090dfffa/c.html            |2025-03-09 14:32:02.651763| -                                    |20250129T073000Z|                                                                                                                                            |xinhuanet.com      |Chinese  |China        |NEGATIVE |
|http://world.people.com.cn/n1/2025/0129/c1002-40410621.html                          |2025-03-09 14:32:02.651763| --  --                           |20250129T020000Z|                                                                                                                                            |world.people.com.cn|Chinese  |China        |NEGATIVE |
|https://news.ifeng.com/c/8gX1YoqwwDd                                                 |2025-03-09 14:32:02.651763|                                                |20250130T023000Z|https://x0.ifengimg.com/ucms/2025_05/B46B03A339D8B9FC271EF531EFE402C09AFD9D1B_size991_w975_h549.png                                         |news.ifeng.com     |Chinese  |China        |NEGATIVE |
+-------------------------------------------------------------------------------------+--------------------------+----------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------+-------------+---------+
only showing top 5 rows

Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark_streaming/spark_streaming.py", line 267, in main
    query.awaitTermination(10)  # Check every 10 seconds
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/sql/streaming/query.py", line 219, in awaitTermination
    return self._jsq.awaitTermination(int(timeout * 1000))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o112.awaitTermination

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark_streaming/spark_streaming.py", line 305, in <module>
    main()
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/spark_streaming/spark_streaming.py", line 273, in main
    time.sleep(10)  # Wait before retrying
    ^^^^^^^^^^^^^^
  File "/Users/rachitmishra/Documents/personal/projs/geopolitics_gdelt_insights/venv/lib/python3.11/site-packages/pyspark/context.py", line 382, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
2025-03-09 14:32:41,350 - INFO - Closing down clientserver connection
25/03/09 14:32:41 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
25/03/09 14:32:41 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1, groupId=spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor] Request joining group due to: consumer pro-actively leaving the group
25/03/09 14:32:41 INFO CassandraConnector: Disconnected from Cassandra cluster.
25/03/09 14:32:41 INFO Metrics: Metrics scheduler closed
25/03/09 14:32:41 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
25/03/09 14:32:41 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
25/03/09 14:32:41 INFO Metrics: Metrics reporters closed
25/03/09 14:32:41 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-0a92f742-cdc3-4436-8449-c8cc2fa1ed6b-464444625-executor-1 unregistered
25/03/09 14:32:41 INFO SparkContext: Invoking stop() from shutdown hook
25/03/09 14:32:41 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/03/09 14:32:41 INFO SparkUI: Stopped Spark web UI at http://192.168.0.201:4040
25/03/09 14:32:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/03/09 14:32:41 INFO MemoryStore: MemoryStore cleared
25/03/09 14:32:41 INFO BlockManager: BlockManager stopped
25/03/09 14:32:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/03/09 14:32:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/03/09 14:32:41 INFO SparkContext: Successfully stopped SparkContext
25/03/09 14:32:41 INFO ShutdownHookManager: Shutdown hook called
25/03/09 14:32:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-a83a7252-b17a-45fa-8803-8663e56bfb5b/pyspark-444141f2-adb9-40e8-85cc-4578858e0e0b
25/03/09 14:32:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-a83a7252-b17a-45fa-8803-8663e56bfb5b
25/03/09 14:32:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/rb/ty7gq05j7qx3czswgl_c0fxw0000gn/T/spark-22e46979-b949-417d-98c4-b83d565b5169
